{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3baddb0b-ec45-4c68-8c8a-68e169e87854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model weights from: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model_retrained.pth\n",
      "model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1157570/1990433863.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F  \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "EPSILON = 0.1       # Max perturbation (for L∞ PGD)\n",
    "ALPHA = 0.01         # Step size per iteration\n",
    "ATTACK_ITERATIONS = 40\n",
    "TARGET_LABEL = 2     # Example target label for the targeted attack\n",
    "\n",
    "# System/Model parameters\n",
    "sys.path.append(\"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/models\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model_retrained.pth\"\n",
    "#IQ_FILE_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/Pluto_10_windows_runs2_3/Pluto_10_2m_run3.iq\"\n",
    "IQ_FILE_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/Pluto_10_windows_runs2_3/Pluto_10_2m_run3.iq\"\n",
    "\n",
    "from attempt2 import resnet50_1d  # Directly import from attempt2.py\n",
    "num_classes = 8  # Change this if your model was trained with a different number of classes\n",
    "\n",
    "# Initialize the model architecture\n",
    "model = resnet50_1d(num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "# Load trained weights\n",
    "print(f\"Loading trained model weights from: {MODEL_PATH}\")\n",
    "state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "print(\"model is loaded\")\n",
    "class IQDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        sample = torch.from_numpy(sample).float()\n",
    "        # Normalize data\n",
    "        magnitude = torch.sqrt(torch.sum(sample**2, dim=1, keepdim=True))\n",
    "        sample = sample / magnitude\n",
    "\n",
    "        label_tensors = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return sample, label_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62635f0a-01c2-4095-a27d-d867efd0e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "WINDOW_SIZE = 10000\n",
    "HOP_SIZE = 500\n",
    "START_INDEX = 4800\n",
    "END_INDEX = 6000\n",
    "\n",
    "def path_loss(signal, n, d1, d2):\n",
    "    scaling = (d1 / d2) ** (n / 2)\n",
    "    return signal * scaling\n",
    "\n",
    "def apply_rician_fading(signal, K=10.0):\n",
    "    \"\"\"\n",
    "    Apply Rician fading to the signal, which is of shape [2, N] (I and Q).\n",
    "    Fading is applied using a K-factor (default 10).\n",
    "    \"\"\"\n",
    "    i_window = signal[:, 0, :]\n",
    "    q_window = signal[:, 1, :]\n",
    "\n",
    "    device = signal.device\n",
    "    dtype = signal.dtype\n",
    "    # Calculate scaling factors\n",
    "    K = torch.tensor(K, dtype=dtype, device=device)\n",
    "    scale_LOS = torch.sqrt(K / (K + 1))\n",
    "    scale_NLOS = torch.sqrt(1 / (K + 1))\n",
    "\n",
    "    # Generate NLOS (Rayleigh) component\n",
    "    real_nlos = torch.randn(i_window.shape, device=device) / torch.sqrt(torch.tensor(2.0, dtype=dtype, device=device))\n",
    "    imag_nlos = torch.randn(i_window.shape, device=device) / torch.sqrt(torch.tensor(2.0, dtype=dtype, device=device))\n",
    "\n",
    "    # LOS component (typically assumed as 1 + 0j for all samples)\n",
    "    real_los = torch.ones(i_window.shape, device=device)\n",
    "    imag_los = torch.zeros(i_window.shape, device=device)\n",
    "\n",
    "    # Total fading coefficients\n",
    "    real_fade = scale_LOS * real_los + scale_NLOS * real_nlos\n",
    "    imag_fade = scale_LOS * imag_los + scale_NLOS * imag_nlos\n",
    "\n",
    "    # Apply Rician fading\n",
    "    faded_real = i_window * real_fade - q_window * imag_fade\n",
    "    faded_imag = i_window * imag_fade + q_window * real_fade\n",
    "\n",
    "    # Reconstruct the faded signal back into a tensor\n",
    "    faded_signal = torch.stack((faded_real, faded_imag), dim=1)\n",
    "\n",
    "    return faded_signal\n",
    "\n",
    "def apply_awgn(signal, noise_std=0.000001):\n",
    "    device = signal.device\n",
    "    dtype = signal.dtype\n",
    "    # Split noise equally between I and Q (to maintain total variance)\n",
    "    per_dim_std = noise_std / torch.sqrt(torch.tensor(2.0, dtype=dtype, device=device))\n",
    "    # Generate i.i.d. Gaussian noise for I and Q\n",
    "    noise = torch.randn_like(signal, device=device) * per_dim_std\n",
    "    # Add noise to the signal\n",
    "    noisy_signal = signal + noise\n",
    "\n",
    "    return noisy_signal\n",
    "\n",
    "def transform_channel_effects(x, chosen_distance=2.0, path_loss_exponent=2.0, reference_distance=1.0, noise_std=0.000001, k=10.0):   \n",
    "    #print(\"Signal original: \", x)\n",
    "    signal_path_loss = path_loss(x, path_loss_exponent, reference_distance, chosen_distance)\n",
    "    #print(\"Signal Path Loss: \", signal_path_loss)\n",
    "    signal_rician = apply_rician_fading(signal_path_loss, k)\n",
    "    #print(\"Signal Rician: \", signal_rician)\n",
    "    signal_awgn = apply_awgn(signal_rician, noise_std)\n",
    "    #print(\"Signal AWGN: \", signal_awgn)\n",
    "    return signal_awgn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ab4c3e6-f0d6-4753-b590-307ae0a62476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sided_nes_attack(\n",
    "    model,\n",
    "    x,                       # clean input (batch size = 1)\n",
    "    perturb,                 # initial perturbation tensor\n",
    "    y,                       # original class label (targeted attack target)\n",
    "    target_label,            # label to spoof as\n",
    "    eps=0.2,\n",
    "    alpha=0.02,\n",
    "    num_iter=40,\n",
    "    num_queries=20,\n",
    "    sigma=0.05,\n",
    "    num_samples=10,\n",
    "    min_distance=1.0,\n",
    "    max_distance=4.0,\n",
    "    path_loss_exponent=2.0,\n",
    "    reference_distance=1.0,\n",
    "    min_noise_std=0.000001,\n",
    "    max_noise_std=0.0001,\n",
    "    min_k=10,\n",
    "    max_k=20\n",
    "):\n",
    "    DEVICE = x.device\n",
    "    x_adv = perturb.clone().detach().to(DEVICE)\n",
    "    best_x_adv = x_adv.clone()\n",
    "    best_confidence = -float('inf')\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        grad_estimate = torch.zeros_like(x_adv)\n",
    "\n",
    "        for _ in range(num_queries): #NES Loop\n",
    "            u = torch.randn_like(x_adv)\n",
    "\n",
    "            # Symmetric perturbations\n",
    "            plus_logits = 0.0\n",
    "            minus_logits = 0.0\n",
    "\n",
    "            for _ in range(num_samples):\n",
    "                # Random EOT parameters\n",
    "                dist = torch.empty(1).uniform_(min_distance, max_distance).item()\n",
    "                k = torch.empty(1).uniform_(min_k, max_k).item()\n",
    "                noise = torch.empty(1).uniform_(min_noise_std, max_noise_std).item()\n",
    "\n",
    "                # EOT transformation for +σu and -σu\n",
    "                x_plus = transform_channel_effects(x_adv + sigma * u, dist, path_loss_exponent, reference_distance, noise, k) + x\n",
    "                x_minus = transform_channel_effects(x_adv - sigma * u, dist, path_loss_exponent, reference_distance, noise, k) + x\n",
    "\n",
    "                plus_logits += model(x_plus)\n",
    "                minus_logits += model(x_minus)\n",
    "\n",
    "            plus_logits /= num_samples\n",
    "            minus_logits /= num_samples\n",
    "\n",
    "            # Probability of target class\n",
    "            p_plus = F.softmax(plus_logits, dim=1)[0, target_label]\n",
    "            p_minus = F.softmax(minus_logits, dim=1)[0, target_label]\n",
    "\n",
    "            grad_estimate += (p_plus - p_minus) * u\n",
    "\n",
    "        # Final gradient estimate scaling\n",
    "        grad_estimate /= (2 * sigma * num_queries)\n",
    "        print(f\"Grad norm: {grad_estimate.norm().item():.4f}\")\n",
    "\n",
    "        # Update and clip\n",
    "        with torch.no_grad():\n",
    "            x_adv = x_adv - alpha * grad_estimate.sign()\n",
    "            x_adv = torch.max(torch.min(x_adv, x + eps), x - eps)\n",
    "\n",
    "        # Evaluate success\n",
    "        with torch.no_grad():\n",
    "            eval_logits = 0.0\n",
    "            for _ in range(num_samples):\n",
    "                dist = torch.empty(1).uniform_(min_distance, max_distance).item()\n",
    "                k = torch.empty(1).uniform_(min_k, max_k).item()\n",
    "                noise = torch.empty(1).uniform_(min_noise_std, max_noise_std).item()\n",
    "\n",
    "                x_t = transform_channel_effects(x_adv, dist, path_loss_exponent, reference_distance, noise, k) + x\n",
    "                eval_logits += model(x_t)\n",
    "\n",
    "            eval_logits /= num_samples\n",
    "            prob = F.softmax(eval_logits, dim=1)[0, target_label].item()\n",
    "\n",
    "            if prob > best_confidence:\n",
    "                best_confidence = prob\n",
    "                best_x_adv = x_adv.clone().detach()\n",
    "\n",
    "            pred = eval_logits.argmax(dim=1).item()\n",
    "            if pred == target_label:\n",
    "                alpha *= 0.25  # or alpha = 0\n",
    "            print(f\"Iter {i+1}/{num_iter} — Target Prob: {prob:.4f} — Pred: {pred} — Success: {pred == target_label}\")\n",
    "\n",
    "    return best_x_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfd68ace-2c40-4f00-97aa-2fd868a2c6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/Pluto_10_windows_runs2_3/Pluto_10_2m_run3.iq\n",
      "True label: 10, Target label: 2\n",
      "Grad norm: 490.5670\n",
      "Iter 1/40 — Target Prob: 0.0125 — Pred: 0 — Success: False\n",
      "Grad norm: 469.2278\n",
      "Iter 2/40 — Target Prob: 0.6311 — Pred: 2 — Success: True\n",
      "Grad norm: 548.0929\n",
      "Iter 3/40 — Target Prob: 0.0321 — Pred: 0 — Success: False\n",
      "Grad norm: 697.3781\n",
      "Iter 4/40 — Target Prob: 0.0023 — Pred: 0 — Success: False\n",
      "Grad norm: 578.1288\n",
      "Iter 5/40 — Target Prob: 0.5231 — Pred: 2 — Success: True\n",
      "Grad norm: 458.5024\n",
      "Iter 6/40 — Target Prob: 0.0003 — Pred: 0 — Success: False\n",
      "Grad norm: 632.6646\n",
      "Iter 7/40 — Target Prob: 0.0000 — Pred: 0 — Success: False\n",
      "Grad norm: 416.3156\n",
      "Iter 8/40 — Target Prob: 0.0004 — Pred: 0 — Success: False\n",
      "Grad norm: 740.1902\n",
      "Iter 9/40 — Target Prob: 0.9166 — Pred: 2 — Success: True\n",
      "Grad norm: 766.1179\n",
      "Iter 10/40 — Target Prob: 0.0015 — Pred: 0 — Success: False\n",
      "Grad norm: 720.0541\n",
      "Iter 11/40 — Target Prob: 0.0001 — Pred: 0 — Success: False\n",
      "Grad norm: 605.8465\n",
      "Iter 12/40 — Target Prob: 0.0003 — Pred: 0 — Success: False\n",
      "Grad norm: 694.0433\n",
      "Iter 13/40 — Target Prob: 0.0108 — Pred: 0 — Success: False\n",
      "Grad norm: 619.9055\n",
      "Iter 14/40 — Target Prob: 0.0005 — Pred: 0 — Success: False\n",
      "Grad norm: 467.3770\n",
      "Iter 15/40 — Target Prob: 0.0002 — Pred: 0 — Success: False\n",
      "Grad norm: 644.5183\n",
      "Iter 16/40 — Target Prob: 0.0000 — Pred: 0 — Success: False\n",
      "Grad norm: 614.0570\n",
      "Iter 17/40 — Target Prob: 0.0014 — Pred: 0 — Success: False\n",
      "Grad norm: 670.8029\n",
      "Iter 18/40 — Target Prob: 0.1014 — Pred: 0 — Success: False\n",
      "Grad norm: 338.6974\n",
      "Iter 19/40 — Target Prob: 0.9986 — Pred: 2 — Success: True\n",
      "Grad norm: 424.7247\n",
      "Iter 20/40 — Target Prob: 0.2757 — Pred: 0 — Success: False\n",
      "Grad norm: 533.4857\n",
      "Iter 21/40 — Target Prob: 0.0000 — Pred: 0 — Success: False\n",
      "Grad norm: 530.3022\n",
      "Iter 22/40 — Target Prob: 0.0229 — Pred: 0 — Success: False\n",
      "Grad norm: 474.2979\n",
      "Iter 23/40 — Target Prob: 0.0005 — Pred: 0 — Success: False\n",
      "Grad norm: 630.8992\n",
      "Iter 24/40 — Target Prob: 0.0030 — Pred: 0 — Success: False\n",
      "Grad norm: 683.2173\n",
      "Iter 25/40 — Target Prob: 0.9532 — Pred: 2 — Success: True\n",
      "Grad norm: 712.3653\n",
      "Iter 26/40 — Target Prob: 0.0000 — Pred: 0 — Success: False\n",
      "Grad norm: 411.9448\n",
      "Iter 27/40 — Target Prob: 0.0000 — Pred: 0 — Success: False\n",
      "Grad norm: 541.4930\n",
      "Iter 28/40 — Target Prob: 0.0117 — Pred: 0 — Success: False\n",
      "Grad norm: 651.6517\n",
      "Iter 29/40 — Target Prob: 0.2544 — Pred: 0 — Success: False\n",
      "Grad norm: 600.4344\n",
      "Iter 30/40 — Target Prob: 0.0094 — Pred: 0 — Success: False\n",
      "Grad norm: 617.6451\n",
      "Iter 31/40 — Target Prob: 0.9468 — Pred: 2 — Success: True\n",
      "Grad norm: 911.7748\n",
      "Iter 32/40 — Target Prob: 0.0000 — Pred: 0 — Success: False\n",
      "Grad norm: 572.6829\n",
      "Iter 33/40 — Target Prob: 0.0786 — Pred: 0 — Success: False\n",
      "Grad norm: 473.0356\n",
      "Iter 34/40 — Target Prob: 0.0000 — Pred: 0 — Success: False\n",
      "Grad norm: 670.3146\n",
      "Iter 35/40 — Target Prob: 0.0471 — Pred: 0 — Success: False\n",
      "Grad norm: 330.4322\n",
      "Iter 36/40 — Target Prob: 0.0000 — Pred: 0 — Success: False\n",
      "Grad norm: 254.9507\n",
      "Iter 37/40 — Target Prob: 0.0000 — Pred: 0 — Success: False\n",
      "Grad norm: 804.6042\n",
      "Iter 38/40 — Target Prob: 0.0003 — Pred: 0 — Success: False\n",
      "Grad norm: 390.1845\n",
      "Iter 39/40 — Target Prob: 0.0003 — Pred: 0 — Success: False\n",
      "Grad norm: 491.2267\n",
      "Iter 40/40 — Target Prob: 0.9596 — Pred: 2 — Success: True\n",
      "Magnitude:  0.07712811\n",
      "Saved EoT PGD *noise* to May27/oneSide3_justin.iq\n"
     ]
    }
   ],
   "source": [
    "def generate_eot_pgd_noise():\n",
    "    print(f\"Loading data from: {IQ_FILE_PATH}\")\n",
    "    label = 10\n",
    "    print(f\"True label: {label}, Target label: {TARGET_LABEL}\")\n",
    "\n",
    "    # Load IQ data\n",
    "    data = np.fromfile(IQ_FILE_PATH, dtype=\"float32\")\n",
    "    real = data[0::2]\n",
    "    imag = data[1::2]\n",
    "    start = (START_INDEX + 1) * HOP_SIZE\n",
    "    end = start + WINDOW_SIZE\n",
    "    i_window = real[start:end]\n",
    "    q_window = imag[start:end]\n",
    "    combined = np.vstack((i_window, q_window))  # [2, N]\n",
    "\n",
    "    # Format into dataset\n",
    "    test_dataset = IQDataset([combined], [label])\n",
    "    data_tensor, label_tensor = test_dataset[0]\n",
    "    data_tensor = data_tensor.unsqueeze(0).to(DEVICE)\n",
    "    #label_tensor = label_tensor.unsqueeze(0).to(DEVICE)\n",
    "    #----------------------------------------------------------\n",
    "    perturbation_tensor = torch.empty((1, 2, WINDOW_SIZE), dtype=torch.float32).uniform_(-0.1, 0.1).to(DEVICE)\n",
    "    label_tensor = torch.tensor([label], dtype=torch.long).to(DEVICE)\n",
    "    #----------------------------------------------------------\n",
    "    min_distance=1.0\n",
    "    max_distance=4.0\n",
    "    min_k = 2\n",
    "    max_k = 2\n",
    "    min_noise_std = 0.000000\n",
    "    max_noise_std = 0.000000\n",
    "    path_loss_exponent=2.0\n",
    "    reference_distance=1.0\n",
    "    EPSILON = 0.1\n",
    "    ALPHA = 0.01\n",
    "    ATTACK_ITERATIONS = 40\n",
    "    if min_distance >= 5.0:\n",
    "        EPSILON = 0.6\n",
    "        ALPHA = 0.021\n",
    "        ATTACK_ITERATIONS = 100\n",
    "\n",
    "    # EoT PGD attack\n",
    "    x_adv = two_sided_nes_attack(\n",
    "    model=model,\n",
    "    x=data_tensor,\n",
    "    perturb=perturbation_tensor,\n",
    "    y=label_tensor,\n",
    "    target_label=TARGET_LABEL,\n",
    "    eps=EPSILON,\n",
    "    alpha=ALPHA,\n",
    "    num_iter=ATTACK_ITERATIONS,\n",
    "    num_queries=20,     # Limit queries\n",
    "    sigma=0.01,         # Perturbation scale\n",
    "    num_samples=5,      # Smaller number due to query limits\n",
    "    min_distance=min_distance,\n",
    "    max_distance=max_distance,\n",
    "    path_loss_exponent=path_loss_exponent,\n",
    "    reference_distance=reference_distance,\n",
    "    min_noise_std=min_noise_std,\n",
    "    max_noise_std=max_noise_std,\n",
    "    min_k=min_k,\n",
    "    max_k=max_k\n",
    "    )\n",
    "\n",
    "    # Save perturbation only\n",
    "    original_np = data_tensor.squeeze().cpu().numpy()\n",
    "\n",
    "    adv_np = x_adv.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    noise_np = adv_np-original_np\n",
    "\n",
    "    interleaved_noise = np.empty(noise_np.shape[1] * 2, dtype=np.float32)\n",
    "    interleaved_noise[0::2] = noise_np[0]\n",
    "    interleaved_noise[1::2] = noise_np[1]\n",
    "\n",
    "    # write out the noise file\n",
    "    save_path = \"May27/oneSide3_justin.iq\"\n",
    "    print(\"Magnitude: \", np.mean(np.abs(interleaved_noise[0::2] + interleaved_noise[1::2] * 1j)))\n",
    "    interleaved_noise.tofile(save_path)\n",
    "    print(f\"Saved EoT PGD *noise* to {save_path}\")\n",
    "\n",
    "\n",
    "generate_eot_pgd_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2804f-ba9e-4cc2-a256-9144fa4c01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    ".07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5130c36f-3deb-47ac-850a-229acfb92dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
