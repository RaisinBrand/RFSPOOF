{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3baddb0b-ec45-4c68-8c8a-68e169e87854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model weights from: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model_retrained.pth\n",
      "model is loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1091547/1990433863.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F  \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "EPSILON = 0.1       # Max perturbation (for Lâˆž PGD)\n",
    "ALPHA = 0.01         # Step size per iteration\n",
    "ATTACK_ITERATIONS = 40\n",
    "TARGET_LABEL = 2     # Example target label for the targeted attack\n",
    "\n",
    "# System/Model parameters\n",
    "sys.path.append(\"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/models\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model_retrained.pth\"\n",
    "#IQ_FILE_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/Pluto_10_windows_runs2_3/Pluto_10_2m_run3.iq\"\n",
    "IQ_FILE_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/Pluto_10_windows_runs2_3/Pluto_10_2m_run3.iq\"\n",
    "\n",
    "from attempt2 import resnet50_1d  # Directly import from attempt2.py\n",
    "num_classes = 8  # Change this if your model was trained with a different number of classes\n",
    "\n",
    "# Initialize the model architecture\n",
    "model = resnet50_1d(num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "# Load trained weights\n",
    "print(f\"Loading trained model weights from: {MODEL_PATH}\")\n",
    "state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "print(\"model is loaded\")\n",
    "class IQDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        sample = torch.from_numpy(sample).float()\n",
    "        # Normalize data\n",
    "        magnitude = torch.sqrt(torch.sum(sample**2, dim=1, keepdim=True))\n",
    "        sample = sample / magnitude\n",
    "\n",
    "        label_tensors = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return sample, label_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62635f0a-01c2-4095-a27d-d867efd0e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "WINDOW_SIZE = 10000\n",
    "HOP_SIZE = 500\n",
    "START_INDEX = 4800\n",
    "END_INDEX = 6000\n",
    "\n",
    "def path_loss(signal, n, d1, d2):\n",
    "    scaling = (d1 / d2) ** (n / 2)\n",
    "    return signal * scaling\n",
    "\n",
    "def apply_rician_fading(signal, K=10.0):\n",
    "    \"\"\"\n",
    "    Apply Rician fading to the signal, which is of shape [2, N] (I and Q).\n",
    "    Fading is applied using a K-factor (default 10).\n",
    "    \"\"\"\n",
    "    i_window = signal[:, 0, :]\n",
    "    q_window = signal[:, 1, :]\n",
    "\n",
    "    device = signal.device\n",
    "    dtype = signal.dtype\n",
    "    # Calculate scaling factors\n",
    "    K = torch.tensor(K, dtype=dtype, device=device)\n",
    "    scale_LOS = torch.sqrt(K / (K + 1))\n",
    "    scale_NLOS = torch.sqrt(1 / (K + 1))\n",
    "\n",
    "    # Generate NLOS (Rayleigh) component\n",
    "    real_nlos = torch.randn(i_window.shape, device=device) / torch.sqrt(torch.tensor(2.0, dtype=dtype, device=device))\n",
    "    imag_nlos = torch.randn(i_window.shape, device=device) / torch.sqrt(torch.tensor(2.0, dtype=dtype, device=device))\n",
    "\n",
    "    # LOS component (typically assumed as 1 + 0j for all samples)\n",
    "    real_los = torch.ones(i_window.shape, device=device)\n",
    "    imag_los = torch.zeros(i_window.shape, device=device)\n",
    "\n",
    "    # Total fading coefficients\n",
    "    real_fade = scale_LOS * real_los + scale_NLOS * real_nlos\n",
    "    imag_fade = scale_LOS * imag_los + scale_NLOS * imag_nlos\n",
    "\n",
    "    # Apply Rician fading\n",
    "    faded_real = i_window * real_fade - q_window * imag_fade\n",
    "    faded_imag = i_window * imag_fade + q_window * real_fade\n",
    "\n",
    "    # Reconstruct the faded signal back into a tensor\n",
    "    faded_signal = torch.stack((faded_real, faded_imag), dim=1)\n",
    "\n",
    "    return faded_signal\n",
    "\n",
    "def apply_awgn(signal, noise_std=0.000001):\n",
    "    device = signal.device\n",
    "    dtype = signal.dtype\n",
    "    # Split noise equally between I and Q (to maintain total variance)\n",
    "    per_dim_std = noise_std / torch.sqrt(torch.tensor(2.0, dtype=dtype, device=device))\n",
    "    # Generate i.i.d. Gaussian noise for I and Q\n",
    "    noise = torch.randn_like(signal, device=device) * per_dim_std\n",
    "    # Add noise to the signal\n",
    "    noisy_signal = signal + noise\n",
    "\n",
    "    return noisy_signal\n",
    "\n",
    "def transform_channel_effects(x, chosen_distance=2.0, path_loss_exponent=2.0, reference_distance=1.0, noise_std=0.000001, k=10.0):   \n",
    "    #print(\"Signal original: \", x)\n",
    "    signal_path_loss = path_loss(x, path_loss_exponent, reference_distance, chosen_distance)\n",
    "    #print(\"Signal Path Loss: \", signal_path_loss)\n",
    "    signal_rician = apply_rician_fading(signal_path_loss, k)\n",
    "    #print(\"Signal Rician: \", signal_rician)\n",
    "    signal_awgn = apply_awgn(signal_rician, noise_std)\n",
    "    #print(\"Signal AWGN: \", signal_awgn)\n",
    "    return signal_awgn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ab4c3e6-f0d6-4753-b590-307ae0a62476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_limited_nes_attack( # most of the params are unchanged from the previous attacks\n",
    "    model,\n",
    "    x,\n",
    "    perturb,\n",
    "    y,\n",
    "    target_label,\n",
    "    eps=0.1,\n",
    "    alpha=0.01,\n",
    "    num_iter=40,\n",
    "    num_queries=20,     # Number of queries for NES black box limiting\n",
    "    sigma=0.01,         # Small perturbation scale\n",
    "    num_samples=10,     # EOT samples (for realism, can be smaller)\n",
    "    min_distance=1.0,\n",
    "    max_distance=4.0,\n",
    "    path_loss_exponent=2.0,\n",
    "    reference_distance=1.0,\n",
    "    min_noise_std=0.000001,\n",
    "    max_noise_std=0.0001,\n",
    "    min_k=10,\n",
    "    max_k=20\n",
    "):\n",
    "    x_adv = perturb.clone().detach().to(DEVICE) \n",
    "    target = torch.full_like(y, target_label).to(DEVICE)\n",
    "\n",
    "    best_x_adv = x_adv.clone().detach()\n",
    "    best_target_confidence = -float('inf')\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        nes_grad_estimate = torch.zeros_like(x_adv)\n",
    "\n",
    "        # NES Gradient Estimation via queries\n",
    "        for _ in range(num_queries): # only prompt in the range of inputted num_queries size\n",
    "            u = torch.randn_like(x_adv) # small perterbation drawn \n",
    "            \n",
    "            # Evaluate model at (x_adv + sigma*u) using EOT for realism\n",
    "            logits_plus = 0\n",
    "            for _ in range(num_samples):\n",
    "                chosen_distance = torch.empty(1).uniform_(min_distance, max_distance).item()\n",
    "                chosen_k = torch.empty(1).uniform_(min_k, max_k).item()\n",
    "                chosen_noise_std = torch.empty(1).uniform_(min_noise_std, max_noise_std).item()\n",
    "                \n",
    "                x_t_plus = transform_channel_effects(\n",
    "                    x_adv + sigma * u,\n",
    "                    chosen_distance,\n",
    "                    path_loss_exponent,\n",
    "                    reference_distance,\n",
    "                    chosen_noise_std,\n",
    "                    chosen_k\n",
    "                ) + x\n",
    "\n",
    "                logits_plus += model(x_t_plus)\n",
    "            \n",
    "            logits_plus /= num_samples #logits_plus is avg model output (logits) across transformations\n",
    "            loss_plus = F.cross_entropy(logits_plus, target)\n",
    "\n",
    "            nes_grad_estimate += loss_plus.item() * u\n",
    "\n",
    "        nes_grad_estimate /= (sigma * num_queries)\n",
    "\n",
    "        # Update adversarial example using NES gradient approximation\n",
    "        with torch.no_grad():\n",
    "            x_adv -= alpha * nes_grad_estimate.sign()\n",
    "            x_adv = torch.max(torch.min(x_adv, x + eps), x - eps)\n",
    "\n",
    "        # Evaluate and track best adversarial example\n",
    "        with torch.no_grad():\n",
    "            logits_eval = 0\n",
    "            for _ in range(num_samples):\n",
    "                chosen_distance = torch.empty(1).uniform_(min_distance, max_distance).item()\n",
    "                chosen_k = torch.empty(1).uniform_(min_k, max_k).item()\n",
    "                chosen_noise_std = torch.empty(1).uniform_(min_noise_std, max_noise_std).item()\n",
    "\n",
    "                x_t_eval = transform_channel_effects(\n",
    "                    x_adv,\n",
    "                    chosen_distance,\n",
    "                    path_loss_exponent,\n",
    "                    reference_distance,\n",
    "                    chosen_noise_std,\n",
    "                    chosen_k\n",
    "                ) + x\n",
    "\n",
    "                logits_eval += model(x_t_eval)\n",
    "\n",
    "            logits_eval /= num_samples\n",
    "            avg_confidence = F.softmax(logits_eval, dim=1)[0, target_label].item()\n",
    "\n",
    "            if avg_confidence > best_target_confidence:\n",
    "                best_target_confidence = avg_confidence\n",
    "                best_x_adv = x_adv.clone().detach()\n",
    "\n",
    "            pred = logits_eval.argmax(dim=1)\n",
    "            success = (pred == target_label).float().mean().item()\n",
    "            print(f\"Iteration {i+1}/{num_iter}: Attack success = {success*100:.2f}%\")\n",
    "\n",
    "    return best_x_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfd68ace-2c40-4f00-97aa-2fd868a2c6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/Pluto_10_windows_runs2_3/Pluto_10_2m_run3.iq\n",
      "True label: 10, Target label: 2\n",
      "Iteration 1/60: Attack success = 100.00%\n",
      "Iteration 2/60: Attack success = 100.00%\n",
      "Iteration 3/60: Attack success = 100.00%\n",
      "Iteration 4/60: Attack success = 100.00%\n",
      "Iteration 5/60: Attack success = 100.00%\n",
      "Iteration 6/60: Attack success = 100.00%\n",
      "Iteration 7/60: Attack success = 100.00%\n",
      "Iteration 8/60: Attack success = 100.00%\n",
      "Iteration 9/60: Attack success = 100.00%\n",
      "Iteration 10/60: Attack success = 100.00%\n",
      "Iteration 11/60: Attack success = 100.00%\n",
      "Iteration 12/60: Attack success = 100.00%\n",
      "Iteration 13/60: Attack success = 100.00%\n",
      "Iteration 14/60: Attack success = 100.00%\n",
      "Iteration 15/60: Attack success = 100.00%\n",
      "Iteration 16/60: Attack success = 100.00%\n",
      "Iteration 17/60: Attack success = 100.00%\n",
      "Iteration 18/60: Attack success = 100.00%\n",
      "Iteration 19/60: Attack success = 100.00%\n",
      "Iteration 20/60: Attack success = 100.00%\n",
      "Iteration 21/60: Attack success = 100.00%\n",
      "Iteration 22/60: Attack success = 100.00%\n",
      "Iteration 23/60: Attack success = 100.00%\n",
      "Iteration 24/60: Attack success = 100.00%\n",
      "Iteration 25/60: Attack success = 100.00%\n",
      "Iteration 26/60: Attack success = 100.00%\n",
      "Iteration 27/60: Attack success = 100.00%\n",
      "Iteration 28/60: Attack success = 100.00%\n",
      "Iteration 29/60: Attack success = 100.00%\n",
      "Iteration 30/60: Attack success = 100.00%\n",
      "Iteration 31/60: Attack success = 100.00%\n",
      "Iteration 32/60: Attack success = 100.00%\n",
      "Iteration 33/60: Attack success = 100.00%\n",
      "Iteration 34/60: Attack success = 100.00%\n",
      "Iteration 35/60: Attack success = 100.00%\n",
      "Iteration 36/60: Attack success = 100.00%\n",
      "Iteration 37/60: Attack success = 100.00%\n",
      "Iteration 38/60: Attack success = 100.00%\n",
      "Iteration 39/60: Attack success = 100.00%\n",
      "Iteration 40/60: Attack success = 100.00%\n",
      "Iteration 41/60: Attack success = 100.00%\n",
      "Iteration 42/60: Attack success = 100.00%\n",
      "Iteration 43/60: Attack success = 100.00%\n",
      "Iteration 44/60: Attack success = 100.00%\n",
      "Iteration 45/60: Attack success = 100.00%\n",
      "Iteration 46/60: Attack success = 100.00%\n",
      "Iteration 47/60: Attack success = 100.00%\n",
      "Iteration 48/60: Attack success = 100.00%\n",
      "Iteration 49/60: Attack success = 100.00%\n",
      "Iteration 50/60: Attack success = 100.00%\n",
      "Iteration 51/60: Attack success = 100.00%\n",
      "Iteration 52/60: Attack success = 100.00%\n",
      "Iteration 53/60: Attack success = 100.00%\n",
      "Iteration 54/60: Attack success = 100.00%\n",
      "Iteration 55/60: Attack success = 100.00%\n",
      "Iteration 56/60: Attack success = 100.00%\n",
      "Iteration 57/60: Attack success = 100.00%\n",
      "Iteration 58/60: Attack success = 100.00%\n",
      "Iteration 59/60: Attack success = 100.00%\n",
      "Iteration 60/60: Attack success = 100.00%\n",
      "Saved EoT PGD *noise* to May27/blackBox.iq\n"
     ]
    }
   ],
   "source": [
    "def generate_eot_pgd_noise():\n",
    "    print(f\"Loading data from: {IQ_FILE_PATH}\")\n",
    "    label = 10\n",
    "    print(f\"True label: {label}, Target label: {TARGET_LABEL}\")\n",
    "\n",
    "    # Load IQ data\n",
    "    data = np.fromfile(IQ_FILE_PATH, dtype=\"float32\")\n",
    "    real = data[0::2]\n",
    "    imag = data[1::2]\n",
    "    start = (START_INDEX + 1) * HOP_SIZE\n",
    "    end = start + WINDOW_SIZE\n",
    "    i_window = real[start:end]\n",
    "    q_window = imag[start:end]\n",
    "    combined = np.vstack((i_window, q_window))  # [2, N]\n",
    "\n",
    "    # Format into dataset\n",
    "    test_dataset = IQDataset([combined], [label])\n",
    "    data_tensor, label_tensor = test_dataset[0]\n",
    "    data_tensor = data_tensor.unsqueeze(0).to(DEVICE)\n",
    "    #label_tensor = label_tensor.unsqueeze(0).to(DEVICE)\n",
    "    #----------------------------------------------------------\n",
    "    perturbation_tensor = torch.empty((1, 2, WINDOW_SIZE), dtype=torch.float32).uniform_(-0.1, 0.1).to(DEVICE)\n",
    "    label_tensor = torch.tensor([label], dtype=torch.long).to(DEVICE)\n",
    "    #----------------------------------------------------------\n",
    "    min_distance=1.0\n",
    "    max_distance=4.0\n",
    "    min_k = 20\n",
    "    max_k = 20\n",
    "    min_noise_std = 0.000001\n",
    "    max_noise_std = 0.000001\n",
    "    path_loss_exponent=2.0\n",
    "    reference_distance=1.0\n",
    "    EPSILON = 0.1\n",
    "    ALPHA = 0.01\n",
    "    ATTACK_ITERATIONS = 60\n",
    "    if min_distance >= 5.0:\n",
    "        EPSILON = 0.6\n",
    "        ALPHA = 0.021\n",
    "        ATTACK_ITERATIONS = 100\n",
    "\n",
    "    # EoT PGD attack\n",
    "    x_adv = query_limited_nes_attack(\n",
    "    model=model,\n",
    "    x=data_tensor,\n",
    "    perturb=perturbation_tensor,\n",
    "    y=label_tensor,\n",
    "    target_label=TARGET_LABEL,\n",
    "    eps=EPSILON,\n",
    "    alpha=ALPHA,\n",
    "    num_iter=ATTACK_ITERATIONS,\n",
    "    num_queries=20,     # Limit queries\n",
    "    sigma=0.01,         # Perturbation scale\n",
    "    num_samples=5,      # Smaller number due to query limits\n",
    "    min_distance=min_distance,\n",
    "    max_distance=max_distance,\n",
    "    path_loss_exponent=path_loss_exponent,\n",
    "    reference_distance=reference_distance,\n",
    "    min_noise_std=min_noise_std,\n",
    "    max_noise_std=max_noise_std,\n",
    "    min_k=min_k,\n",
    "    max_k=max_k\n",
    "    )\n",
    "\n",
    "    # Save perturbation only\n",
    "    original_np = data_tensor.squeeze().cpu().numpy()\n",
    "\n",
    "    adv_np = x_adv.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    noise_np = adv_np-original_np\n",
    "\n",
    "    interleaved_noise = np.empty(noise_np.shape[1] * 2, dtype=np.float32)\n",
    "    interleaved_noise[0::2] = noise_np[0]\n",
    "    interleaved_noise[1::2] = noise_np[1]\n",
    "\n",
    "    # write out the noise file\n",
    "    save_path = \"May27/blackBox.iq\"\n",
    "    interleaved_noise.tofile(save_path)\n",
    "    print(f\"Saved EoT PGD *noise* to {save_path}\")\n",
    "\n",
    "\n",
    "generate_eot_pgd_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2804f-ba9e-4cc2-a256-9144fa4c01b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
