{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67486927-e138-4105-9d17-b308a17baf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model weights from: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model_retrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_342067/4002822919.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet1D(\n",
       "  (conv1): Conv1d(2, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck1D(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck1D(\n",
       "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Bottleneck1D(\n",
       "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck1D(\n",
       "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck1D(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Bottleneck1D(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Bottleneck1D(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck1D(\n",
       "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck1D(\n",
       "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Bottleneck1D(\n",
       "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=2048, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F  \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "EPSILON = 0.1       # Max perturbation (for L∞ PGD)\n",
    "ALPHA = 0.01         # Step size per iteration\n",
    "ATTACK_ITERATIONS = 40\n",
    "TARGET_LABEL = 2     # Example target label for the targeted attack\n",
    "\n",
    "# System/Model parameters\n",
    "sys.path.append(\"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/models\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model_retrained.pth\"\n",
    "#IQ_FILE_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/Pluto_10_windows_runs2_3/Pluto_10_2m_run3.iq\"\n",
    "IQ_FILE_PATH = \"May22Test/Pluto10_2m.iq\"\n",
    "\n",
    "from attempt2 import resnet50_1d  # Directly import from attempt2.py\n",
    "num_classes = 8  # Change this if your model was trained with a different number of classes\n",
    "\n",
    "# Initialize the model architecture\n",
    "model = resnet50_1d(num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "# Load trained weights\n",
    "print(f\"Loading trained model weights from: {MODEL_PATH}\")\n",
    "state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f389dff9-ba8b-4a9a-8c12-775b9e997549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IQDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        sample = torch.from_numpy(sample).float()\n",
    "        # Normalize data\n",
    "        magnitude = torch.sqrt(torch.sum(sample**2, dim=1, keepdim=True))\n",
    "        sample = sample / magnitude\n",
    "\n",
    "        label_tensors = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return sample, label_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7d825e-990c-477c-9efc-93e3cb2af9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "WINDOW_SIZE = 10000\n",
    "HOP_SIZE = 500\n",
    "START_INDEX = 4800\n",
    "END_INDEX = 6000\n",
    "\n",
    "def path_loss(signal, n, d1, d2):\n",
    "    scaling = (d1 / d2) ** (n / 2)\n",
    "    return signal * scaling\n",
    "\n",
    "def apply_rician_fading(signal, K=10.0):\n",
    "    \"\"\"\n",
    "    Apply Rician fading to the signal, which is of shape [2, N] (I and Q).\n",
    "    Fading is applied using a K-factor (default 10).\n",
    "    \"\"\"\n",
    "    i_window = signal[:, 0, :]\n",
    "    q_window = signal[:, 1, :]\n",
    "\n",
    "    device = signal.device\n",
    "    dtype = signal.dtype\n",
    "    # Calculate scaling factors\n",
    "    K = torch.tensor(K, dtype=dtype, device=device)\n",
    "    scale_LOS = torch.sqrt(K / (K + 1))\n",
    "    scale_NLOS = torch.sqrt(1 / (K + 1))\n",
    "\n",
    "    # Generate NLOS (Rayleigh) component\n",
    "    real_nlos = torch.randn(i_window.shape, device=device) / torch.sqrt(torch.tensor(2.0, dtype=dtype, device=device))\n",
    "    imag_nlos = torch.randn(i_window.shape, device=device) / torch.sqrt(torch.tensor(2.0, dtype=dtype, device=device))\n",
    "\n",
    "    # LOS component (typically assumed as 1 + 0j for all samples)\n",
    "    real_los = torch.ones(i_window.shape, device=device)\n",
    "    imag_los = torch.zeros(i_window.shape, device=device)\n",
    "\n",
    "    # Total fading coefficients\n",
    "    real_fade = scale_LOS * real_los + scale_NLOS * real_nlos\n",
    "    imag_fade = scale_LOS * imag_los + scale_NLOS * imag_nlos\n",
    "\n",
    "    # Apply Rician fading\n",
    "    faded_real = i_window * real_fade - q_window * imag_fade\n",
    "    faded_imag = i_window * imag_fade + q_window * real_fade\n",
    "\n",
    "    # Reconstruct the faded signal back into a tensor\n",
    "    faded_signal = torch.stack((faded_real, faded_imag), dim=1)\n",
    "\n",
    "    return faded_signal\n",
    "\n",
    "def apply_awgn(signal, noise_std=0.000001):\n",
    "    device = signal.device\n",
    "    dtype = signal.dtype\n",
    "    # Split noise equally between I and Q (to maintain total variance)\n",
    "    per_dim_std = noise_std / torch.sqrt(torch.tensor(2.0, dtype=dtype, device=device))\n",
    "    # Generate i.i.d. Gaussian noise for I and Q\n",
    "    noise = torch.randn_like(signal, device=device) * per_dim_std\n",
    "    # Add noise to the signal\n",
    "    noisy_signal = signal + noise\n",
    "\n",
    "    return noisy_signal\n",
    "\n",
    "def transform_channel_effects(x, chosen_distance=2.0, path_loss_exponent=2.0, reference_distance=1.0, noise_std=0.000001, k=10.0):   \n",
    "    #print(\"Signal original: \", x)\n",
    "    signal_path_loss = path_loss(x, path_loss_exponent, reference_distance, chosen_distance)\n",
    "    #print(\"Signal Path Loss: \", signal_path_loss)\n",
    "    signal_rician = apply_rician_fading(signal_path_loss, k)\n",
    "    #print(\"Signal Rician: \", signal_rician)\n",
    "    signal_awgn = apply_awgn(signal_rician, noise_std)\n",
    "    #print(\"Signal AWGN: \", signal_awgn)\n",
    "    return signal_awgn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d681ac-5c37-4371-837f-a9a5411fe41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def targeted_eot_pgd_attack(\n",
    "    model,\n",
    "    x,\n",
    "    perturb,\n",
    "    y,\n",
    "    target_label,\n",
    "    eps=0.1,\n",
    "    alpha=0.01,\n",
    "    num_iter=40,\n",
    "    num_samples=10,\n",
    "    min_distance=1.0,\n",
    "    max_distance=4.0,\n",
    "    path_loss_exponent=2.0,\n",
    "    reference_distance=1.0,\n",
    "    min_noise_std=0.000001,\n",
    "    max_noise_std=0.0001,\n",
    "    min_k=10,\n",
    "    max_k=20\n",
    "):\n",
    "    x_adv = perturb.clone().detach().requires_grad_(True).to(DEVICE)\n",
    "    target = torch.full_like(y, target_label)\n",
    "\n",
    "    best_x_adv = x_adv.clone().detach()\n",
    "    best_target_confidence = -float('inf')\n",
    "    # PGD Iterations\n",
    "    for i in range(num_iter):\n",
    "        total_grad = torch.zeros_like(x_adv)\n",
    "        grads = []\n",
    "        # EOT Iterations\n",
    "        for _ in range(num_samples):\n",
    "            all_logits = []\n",
    "            # Choose a random distance between min and max, for this EOT iteration\n",
    "            chosen_distance = torch.empty(1).uniform_(min_distance, max_distance + 0.0000001).item()\n",
    "            chosen_k = torch.empty(1).uniform_(min_k, max_k + 0.0000001).item()\n",
    "            chosen_noise_std = torch.empty(1).uniform_(min_noise_std, max_noise_std + 0.0000001).item()\n",
    "            x_t = transform_channel_effects(\n",
    "                x_adv,\n",
    "                chosen_distance=chosen_distance,\n",
    "                path_loss_exponent=path_loss_exponent,\n",
    "                reference_distance=reference_distance,\n",
    "                noise_std=chosen_noise_std,\n",
    "                k=chosen_k\n",
    "            )\n",
    "            x_combined = x_t + x\n",
    "            logits = model(x_combined)\n",
    "            all_logits.append(logits)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "\n",
    "            grad = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "            grads.append(grad.detach())\n",
    "            total_grad += grad\n",
    "\n",
    "        grads_tensor = torch.stack(grads)\n",
    "        grad_variance = grads_tensor.var(dim=0).mean().item()\n",
    "        print(f\"PGD step {i + 1}/{num_iter}: gradient variance = {grad_variance:.4e}\")\n",
    "        avg_grad = total_grad / num_samples\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_adv -= alpha * avg_grad.sign()\n",
    "            x_adv = torch.max(torch.min(x_adv, x + eps), x - eps)\n",
    "            x_adv = x_adv.detach().clone().requires_grad_(True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_logits = torch.stack(all_logits).mean(dim=0)\n",
    "            target_confidence = F.softmax(avg_logits, dim=1)[:, target_label]  # shape: [batch]\n",
    "            avg_conf = target_confidence.mean().item()\n",
    "\n",
    "            if avg_conf > best_target_confidence:\n",
    "                best_target_confidence = avg_conf\n",
    "                best_x_adv = x_adv.clone().detach()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Choose a random distance between min and max, for this EOT iteration\n",
    "            chosen_distance = torch.empty(1).uniform_(min_distance, max_distance + 0.0000001).item()\n",
    "            chosen_k = torch.empty(1).uniform_(min_k, max_k + 0.0000001).item()\n",
    "            chosen_noise_std = torch.empty(1).uniform_(min_noise_std, max_noise_std + 0.0000001).item()\n",
    "            x_t = transform_channel_effects(\n",
    "                x_adv,\n",
    "                chosen_distance=chosen_distance,\n",
    "                path_loss_exponent=path_loss_exponent,\n",
    "                reference_distance=reference_distance,\n",
    "                noise_std=chosen_noise_std,\n",
    "                k=chosen_k\n",
    "            )\n",
    "            x_combined = x_t + x\n",
    "            pred = model(x_combined).argmax(dim=1)\n",
    "            success = (pred == target).float().mean().item()\n",
    "            print(f\"Attack success rate: {success * 100:.2f}%\")\n",
    "\n",
    "    return best_x_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e397fc96-c869-45bb-9d31-09d9ae97693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: bPluto/brandanpluto10_2m.iq\n",
      "True label: 10, Target label: 2\n",
      "PGD step 1/40: gradient variance = 2.7975e+01\n",
      "Attack success rate: 100.00%\n",
      "PGD step 2/40: gradient variance = 3.8594e-05\n",
      "Attack success rate: 100.00%\n",
      "PGD step 3/40: gradient variance = 5.5417e-35\n",
      "Attack success rate: 100.00%\n",
      "PGD step 4/40: gradient variance = 1.2929e-19\n",
      "Attack success rate: 100.00%\n",
      "PGD step 5/40: gradient variance = 1.5370e-27\n",
      "Attack success rate: 100.00%\n",
      "PGD step 6/40: gradient variance = 6.9379e-01\n",
      "Attack success rate: 100.00%\n",
      "PGD step 7/40: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 8/40: gradient variance = 1.1173e-06\n",
      "Attack success rate: 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 79\u001b[0m\n\u001b[1;32m     75\u001b[0m     interleaved_noise\u001b[38;5;241m.\u001b[39mtofile(save_path)\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved EoT PGD *noise* to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m \u001b[43mgenerate_eot_pgd_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m, in \u001b[0;36mgenerate_eot_pgd_noise\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     ATTACK_ITERATIONS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# EoT PGD attack\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m x_adv \u001b[38;5;241m=\u001b[39m \u001b[43mtargeted_eot_pgd_attack\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mperturb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mperturbation_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTARGET_LABEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPSILON\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mALPHA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mATTACK_ITERATIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_loss_exponent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_loss_exponent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_noise_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_noise_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_noise_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_noise_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_k\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Save perturbation only\u001b[39;00m\n\u001b[1;32m     63\u001b[0m original_np \u001b[38;5;241m=\u001b[39m data_tensor\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m, in \u001b[0;36mtargeted_eot_pgd_attack\u001b[0;34m(model, x, perturb, y, target_label, eps, alpha, num_iter, num_samples, min_distance, max_distance, path_loss_exponent, reference_distance, min_noise_std, max_noise_std, min_k, max_k)\u001b[0m\n\u001b[1;32m     38\u001b[0m x_t \u001b[38;5;241m=\u001b[39m transform_channel_effects(\n\u001b[1;32m     39\u001b[0m     x_adv,\n\u001b[1;32m     40\u001b[0m     chosen_distance\u001b[38;5;241m=\u001b[39mchosen_distance,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     k\u001b[38;5;241m=\u001b[39mchosen_k\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     46\u001b[0m x_combined \u001b[38;5;241m=\u001b[39m x_t \u001b[38;5;241m+\u001b[39m x\n\u001b[0;32m---> 47\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_combined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m all_logits\u001b[38;5;241m.\u001b[39mappend(logits)\n\u001b[1;32m     49\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, target)\n",
      "File \u001b[0;32m~/miniconda3/envs/new3d/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/new3d/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/models/attempt2.py:98\u001b[0m, in \u001b[0;36mResNet1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     96\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m     97\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m---> 98\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n\u001b[1;32m    101\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/new3d/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/new3d/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/new3d/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/new3d/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/new3d/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/models/attempt2.py:48\u001b[0m, in \u001b[0;36mBottleneck1D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     46\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m---> 48\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     49\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)))\n\u001b[1;32m     50\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(out))\n",
      "File \u001b[0;32m~/miniconda3/envs/new3d/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/new3d/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/new3d/lib/python3.11/site-packages/torch/nn/modules/conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/new3d/lib/python3.11/site-packages/torch/nn/modules/conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[1;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[0;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def generate_eot_pgd_noise():\n",
    "    print(f\"Loading data from: {IQ_FILE_PATH}\")\n",
    "    label = 10\n",
    "    print(f\"True label: {label}, Target label: {TARGET_LABEL}\")\n",
    "\n",
    "    # Load IQ data\n",
    "    data = np.fromfile(IQ_FILE_PATH, dtype=\"float32\")\n",
    "    real = data[0::2]\n",
    "    imag = data[1::2]\n",
    "    start = (START_INDEX + 1) * HOP_SIZE\n",
    "    end = start + WINDOW_SIZE\n",
    "    i_window = real[start:end]\n",
    "    q_window = imag[start:end]\n",
    "    combined = np.vstack((i_window, q_window))  # [2, N]\n",
    "\n",
    "    # Format into dataset\n",
    "    test_dataset = IQDataset([combined], [label])\n",
    "    data_tensor, label_tensor = test_dataset[0]\n",
    "    data_tensor = data_tensor.unsqueeze(0).to(DEVICE)\n",
    "    #label_tensor = label_tensor.unsqueeze(0).to(DEVICE)\n",
    "    #----------------------------------------------------------\n",
    "    perturbation_tensor = torch.empty((1, 2, WINDOW_SIZE), dtype=torch.float32).uniform_(-0.1, 0.1).to(DEVICE)\n",
    "    label_tensor = torch.tensor([label], dtype=torch.long).to(DEVICE)\n",
    "    #----------------------------------------------------------\n",
    "    min_distance=1.0\n",
    "    max_distance=4.0\n",
    "    min_k = 20\n",
    "    max_k = 20\n",
    "    min_noise_std = 0.000001\n",
    "    max_noise_std = 0.000001\n",
    "    path_loss_exponent=2.0\n",
    "    reference_distance=1.0\n",
    "    EPSILON = 0.1\n",
    "    ALPHA = 0.01\n",
    "    ATTACK_ITERATIONS = 40\n",
    "    if min_distance >= 5.0:\n",
    "        EPSILON = 0.6\n",
    "        ALPHA = 0.021\n",
    "        ATTACK_ITERATIONS = 100\n",
    "\n",
    "    # EoT PGD attack\n",
    "    x_adv = targeted_eot_pgd_attack(\n",
    "        model=model,\n",
    "        x=data_tensor,\n",
    "        perturb=perturbation_tensor,\n",
    "        y=label_tensor,\n",
    "        target_label=TARGET_LABEL,\n",
    "        eps=EPSILON,\n",
    "        alpha=ALPHA,\n",
    "        num_iter=ATTACK_ITERATIONS,\n",
    "        num_samples=10,\n",
    "        min_distance=min_distance,\n",
    "        max_distance=max_distance,\n",
    "        path_loss_exponent=path_loss_exponent,\n",
    "        reference_distance=reference_distance,\n",
    "        min_noise_std=min_noise_std,\n",
    "        max_noise_std=max_noise_std,\n",
    "        min_k=min_k,\n",
    "        max_k=max_k\n",
    "    )\n",
    "\n",
    "    # Save perturbation only\n",
    "    original_np = data_tensor.squeeze().cpu().numpy()\n",
    "\n",
    "    adv_np = x_adv.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    noise_np = adv_np-original_np\n",
    "\n",
    "    interleaved_noise = np.empty(noise_np.shape[1] * 2, dtype=np.float32)\n",
    "    interleaved_noise[0::2] = noise_np[0]\n",
    "    interleaved_noise[1::2] = noise_np[1]\n",
    "\n",
    "    # write out the noise file\n",
    "    save_path = \"May22/baseline.iq\"\n",
    "    interleaved_noise.tofile(save_path)\n",
    "    print(f\"Saved EoT PGD *noise* to {save_path}\")\n",
    "\n",
    "\n",
    "generate_eot_pgd_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "398b200d-e48f-475c-a9c5-1e2d57e83f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def targeted_eot_pgd_attack2(\n",
    "    model,\n",
    "    x,\n",
    "    perturb,\n",
    "    y,\n",
    "    target_label,\n",
    "    eps=0.1,\n",
    "    alpha=0.01,\n",
    "    num_iter=40,\n",
    "    num_samples=10,\n",
    "    min_distance=1.0,\n",
    "    max_distance=4.0,\n",
    "    path_loss_exponent=2.0,\n",
    "    reference_distance=1.0,\n",
    "    min_noise_std=0.000001,\n",
    "    max_noise_std=0.0001,\n",
    "    min_k=10,\n",
    "    max_k=20\n",
    "):\n",
    "    x_acc = perturb.clone().detach().requires_grad_(True).to(DEVICE)\n",
    "    target = torch.full_like(y, target_label)\n",
    "\n",
    "    best_x_acc = x_acc.clone().detach()\n",
    "    best_target_confidence = -float('inf')\n",
    "    # PGD Iterations\n",
    "    for i in range(num_iter):\n",
    "        total_grad = torch.zeros_like(x_acc)\n",
    "        grads = []\n",
    "        # EOT Iterations\n",
    "        for _ in range(num_samples):\n",
    "            all_logits = []\n",
    "            # Choose a random distance between min and max, for this EOT iteration\n",
    "            chosen_distance = torch.empty(1).uniform_(min_distance, max_distance + 0.0000001).item()\n",
    "            chosen_k = torch.empty(1).uniform_(min_k, max_k + 0.0000001).item()\n",
    "            chosen_noise_std = torch.empty(1).uniform_(min_noise_std, max_noise_std + 0.0000001).item()\n",
    "            x_t = transform_channel_effects(\n",
    "                x_acc,\n",
    "                chosen_distance=chosen_distance,\n",
    "                path_loss_exponent=path_loss_exponent,\n",
    "                reference_distance=reference_distance,\n",
    "                noise_std=chosen_noise_std,\n",
    "                k=chosen_k\n",
    "            )\n",
    "            d_tx   = float(torch.empty(1).uniform_(min_distance, max_distance))\n",
    "            sigma_tx   = float(torch.empty(1).uniform_(min_noise_std, max_noise_std))\n",
    "            k_tx   = float(torch.empty(1).uniform_(min_k, max_k))\n",
    "            x_tx_t = transform_channel_effects(\n",
    "                x,\n",
    "                chosen_distance=d_tx,\n",
    "                path_loss_exponent=path_loss_exponent,\n",
    "                reference_distance=reference_distance,\n",
    "                noise_std=sigma_tx,\n",
    "                k=k_tx\n",
    "            )\n",
    "            x_combined = x_t + x_tx_t\n",
    "            logits = model(x_combined)\n",
    "            all_logits.append(logits)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "\n",
    "            grad = torch.autograd.grad(loss, x_acc, retain_graph=False, create_graph=False)[0]\n",
    "            grads.append(grad.detach())\n",
    "            total_grad += grad\n",
    "\n",
    "        grads_tensor = torch.stack(grads)\n",
    "        grad_variance = grads_tensor.var(dim=0).mean().item()\n",
    "        print(f\"PGD step {i + 1}/{num_iter}: gradient variance = {grad_variance:.4e}\")\n",
    "        avg_grad = total_grad / num_samples\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_acc -= alpha * avg_grad.sign()\n",
    "            x_acc = torch.max(torch.min(x_acc, x + eps), x - eps)\n",
    "            x_acc = x_acc.detach().clone().requires_grad_(True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_logits = torch.stack(all_logits).mean(dim=0)\n",
    "            target_confidence = F.softmax(avg_logits, dim=1)[:, target_label]  # shape: [batch]\n",
    "            avg_conf = target_confidence.mean().item()\n",
    "\n",
    "            if avg_conf > best_target_confidence:\n",
    "                best_target_confidence = avg_conf\n",
    "                best_x_acc = x_acc.clone().detach()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Choose a random distance between min and max, for this EOT iteration\n",
    "            chosen_distance = torch.empty(1).uniform_(min_distance, max_distance + 0.0000001).item()\n",
    "            chosen_k = torch.empty(1).uniform_(min_k, max_k + 0.0000001).item()\n",
    "            chosen_noise_std = torch.empty(1).uniform_(min_noise_std, max_noise_std + 0.0000001).item()\n",
    "            x_t = transform_channel_effects(\n",
    "                x_acc,\n",
    "                chosen_distance=chosen_distance,\n",
    "                path_loss_exponent=path_loss_exponent,\n",
    "                reference_distance=reference_distance,\n",
    "                noise_std=chosen_noise_std,\n",
    "                k=chosen_k\n",
    "            )\n",
    "            x_combined = x_t + x\n",
    "            pred = model(x_combined).argmax(dim=1)\n",
    "            success = (pred == target).float().mean().item()\n",
    "            print(f\"Attack success rate: {success * 100:.2f}%\")\n",
    "\n",
    "    return best_x_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5984ece-a10e-4a77-be33-911f67344cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
