{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "158a3d4c-0023-4790-888b-d692a417d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F  \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "effc5747-0e84-4f71-895c-066414353d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 0.1       # Max perturbation (for L∞ PGD)\n",
    "ALPHA = 0.01         # Step size per iteration\n",
    "ATTACK_ITERATIONS = 40\n",
    "TARGET_LABEL = 1     # Example target label for the targeted attack\n",
    "\n",
    "# System/Model parameters\n",
    "sys.path.append(\"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/models\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model_retrained.pth\"\n",
    "\n",
    "IQ_FILE_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/Pluto_10_windows_runs2_3/Pluto_10_2m_run3.iq\"\n",
    "\n",
    "#IQ_FILE_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/1m_2m/Pluto_0_1m_run3.iq\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "244ca700-ca37-452a-be48-0392caac522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IQDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        sample = torch.from_numpy(sample).float()\n",
    "        # Normalize data\n",
    "        magnitude = torch.sqrt(torch.sum(sample**2, dim=1, keepdim=True))\n",
    "        sample = sample / magnitude\n",
    "\n",
    "        label_tensors = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return sample, label_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e62b5-a9fd-491c-ac68-21efc864cb58",
   "metadata": {},
   "source": [
    "Test clean sample of class 1 on classifier to ensure that classifier is working for target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e65c33d4-7d72-4113-b0da-6f3c2d51b5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3731746/1250051776.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/1m_2m/Pluto_1_2m_run3.iq\n",
      "[Pluto_1_2m_run3.iq] Accuracy on label 1: 95.75% | Mismatches: 51 / 1200\n"
     ]
    }
   ],
   "source": [
    "TRUE_IQ_FILE_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/1m_2m/Pluto_1_2m_run3.iq\"\n",
    "BATCH_SIZE = 16\n",
    "WINDOW_SIZE = 10000\n",
    "HOP_SIZE = 500\n",
    "START_INDEX = 4800\n",
    "END_INDEX = 6000\n",
    "\n",
    "# Initialize and load model\n",
    "model = resnet50_1d(num_classes=8)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "fname = os.path.basename(TRUE_IQ_FILE_PATH)\n",
    "print(f\"\\nProcessing file: {TRUE_IQ_FILE_PATH}\")\n",
    "\n",
    "# Extract label from filename: Pluto_#_...\n",
    "try:\n",
    "    target_label = int(fname.split(\"_\")[1])\n",
    "except (IndexError, ValueError):\n",
    "    print(f\"  Warning: could not parse label from filename: {fname}\")\n",
    "    \n",
    "\n",
    "# Load IQ data\n",
    "data = np.fromfile(TRUE_IQ_FILE_PATH, dtype=\"float32\")\n",
    "real_part = data[0::2]\n",
    "imag_part = data[1::2]\n",
    "\n",
    "test_data_tensors = []\n",
    "test_label_tensors = []\n",
    "\n",
    "# Sliding window generation\n",
    "for x in range(START_INDEX, END_INDEX):\n",
    "    start = (x + 1) * HOP_SIZE\n",
    "    end = start + WINDOW_SIZE\n",
    "    if end > len(real_part): break\n",
    "\n",
    "    i_window = real_part[start:end]\n",
    "    q_window = imag_part[start:end]\n",
    "    combined = np.vstack((i_window, q_window))  # [2, WINDOW_SIZE]\n",
    "    test_data_tensors.append(combined)\n",
    "    test_label_tensors.append(target_label)\n",
    "\n",
    "if not test_data_tensors:\n",
    "    print(f\"Skipping {fname}: not enough valid IQ segments.\")\n",
    "    \n",
    "\n",
    "# Stack and shuffle\n",
    "test_data_tensors = np.stack(test_data_tensors, axis=0)\n",
    "test_label_tensors = np.array(test_label_tensors)\n",
    "indices = np.random.permutation(len(test_data_tensors))\n",
    "test_data = test_data_tensors[indices]\n",
    "test_labels = test_label_tensors[indices]\n",
    "\n",
    "# Create Dataset + Loader\n",
    "test_dataset = IQDataset(test_data, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Evaluate\n",
    "correct = 0\n",
    "total = 0\n",
    "mismatch_count = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        mismatch_count += (predicted != labels).sum().item()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "acc = correct / total * 100\n",
    "print(f\"[{fname}] Accuracy on label {TARGET_LABEL}: {acc:.2f}% | Mismatches: {mismatch_count} / {total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "827b8886-956f-435c-8afb-dd736bfbf2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def targeted_pgd_attack(\n",
    "    model,\n",
    "    iq_input,\n",
    "    true_labels,\n",
    "    target_class,\n",
    "    epsilon,\n",
    "    alpha,\n",
    "    num_iterations,\n",
    "    device='cuda'\n",
    "):\n",
    "    model.eval()\n",
    "    iq_input = iq_input.to(device)\n",
    "    norm = torch.norm(iq_input, dim=(1, 2), keepdim=True)\n",
    "    iq_input = iq_input / (norm + 1e-8)  # Normalize input before attack\n",
    "    \n",
    "    if isinstance(target_class, int):\n",
    "        target_labels = torch.full_like(true_labels, target_class).to(device)\n",
    "    else:\n",
    "        target_labels = target_class.to(device)\n",
    "\n",
    "    adv_iq = iq_input.clone().detach()\n",
    "    adv_iq.requires_grad = True\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        outputs = model(adv_iq)\n",
    "        loss = -nn.CrossEntropyLoss()(outputs, target_labels)  # Targeted attack\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        gradient = adv_iq.grad.data\n",
    "        adv_iq = adv_iq.detach() + alpha * gradient.sign()\n",
    "        adv_iq = torch.min(torch.max(adv_iq, iq_input - epsilon), iq_input + epsilon)\n",
    "\n",
    "        adv_iq.requires_grad = True\n",
    "\n",
    "    return adv_iq.detach()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d468744d-a027-4079-b50a-b9f44e695a14",
   "metadata": {},
   "source": [
    "Create and save sample, targeted class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4105454a-4988-4e49-9459-5bff59047397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/Pluto_10_windows_runs2_3/Pluto_10_2m_run3.iq\n",
      "True label: 10, Target label: 1\n",
      "Original prediction: 1, Confidence: 0.6514\n",
      "Adversarial prediction: 1, Confidence: 1.0000\n",
      "✅ Saved PGD noise only to: Apr16/pgd_noise_pluto0_target1.iq\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(f\"Loading data from: {IQ_FILE_PATH}\")\n",
    "\n",
    "    # Extract true label from filename\n",
    "    label = int(os.path.basename(IQ_FILE_PATH).split(\"_\")[1])\n",
    "    print(f\"True label: {label}, Target label: {TARGET_LABEL}\")\n",
    "\n",
    "    # Load and format IQ data\n",
    "    data = np.fromfile(IQ_FILE_PATH, dtype=\"float32\")\n",
    "    real = data[0::2]\n",
    "    imag = data[1::2]\n",
    "\n",
    "    start = (START_INDEX + 1) * HOP_SIZE\n",
    "    end = start + WINDOW_SIZE\n",
    "    i_window = real[start:end]\n",
    "    q_window = imag[start:end]\n",
    "    combined = np.vstack((i_window, q_window))  # Shape: [2, N]\n",
    "\n",
    "    # Normalize the signal\n",
    "    combined = combined / (np.linalg.norm(combined) + 1e-8)\n",
    "\n",
    "    # Wrap in Dataset for consistent preprocessing\n",
    "    test_dataset = IQDataset([combined], [label])\n",
    "    data_tensor, label_tensor = test_dataset[0]\n",
    "    data_tensor = data_tensor.unsqueeze(0).to(DEVICE)\n",
    "    label_tensor = label_tensor.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    # Prediction before attack\n",
    "    with torch.no_grad():\n",
    "        logits = model(data_tensor)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        orig_pred = torch.argmax(probs, dim=1)\n",
    "        orig_conf = probs.max(dim=1).values\n",
    "\n",
    "    print(f\"Original prediction: {orig_pred.item()}, Confidence: {orig_conf.item():.4f}\")\n",
    "\n",
    "    # Run targeted PGD attack\n",
    "    x_adv = targeted_pgd_attack(\n",
    "        model=model,\n",
    "        iq_input=data_tensor,\n",
    "        true_labels=label_tensor,\n",
    "        target_class=TARGET_LABEL,\n",
    "        epsilon=EPSILON,\n",
    "        alpha=ALPHA,\n",
    "        num_iterations=ATTACK_ITERATIONS,\n",
    "        device=DEVICE\n",
    "    )\n",
    "\n",
    "    # Prediction after attack\n",
    "    with torch.no_grad():\n",
    "        logits_adv = model(x_adv)\n",
    "        probs_adv = F.softmax(logits_adv, dim=1)\n",
    "        adv_pred = torch.argmax(probs_adv, dim=1)\n",
    "        adv_conf = probs_adv.max(dim=1).values\n",
    "\n",
    "    print(f\"Adversarial prediction: {adv_pred.item()}, Confidence: {adv_conf.item():.4f}\")\n",
    "\n",
    "    # Save full adversarial signal (not just the noise)\n",
    "    adv_np = x_adv.squeeze().cpu().numpy()       # shape [2, N]\n",
    "    orig_np = data_tensor.squeeze().cpu().numpy()  # shape [2, N]\n",
    "    \n",
    "    perturbation = adv_np - orig_np\n",
    "    interleaved = np.empty(perturbation.shape[1] * 2, dtype=np.float32)\n",
    "    interleaved[0::2] = perturbation[0]\n",
    "    interleaved[1::2] = perturbation[1]\n",
    "    \n",
    "    save_path = \"Apr16/pgd_noise_pluto0_target1.iq\"\n",
    "    interleaved.tofile(save_path)\n",
    "    print(f\"Saved PGD noise only to: {save_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d351bb0-befe-4838-b7f2-d21a6416dcce",
   "metadata": {},
   "source": [
    "Test the newly generated sample, make sure its using the newest noise instead of old one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2729b314-6d77-4873-a3e2-c9574b6ee33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3731746/1405894345.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IQ window length: 10000\n",
      "Reconstructed PGD prediction: 3, confidence: 1.0000\n",
      "❌ Attack failed.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "# Your model and constants\n",
    "ADV_IQ_FILE_PATH = \"Apr16/pluto10_to_target1_noise.iq\"  # replace with actual path\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "WINDOW_SIZE = 4096  # expected IQ window size\n",
    "TARGET_LABEL = 1    # expected spoofed target label\n",
    "\n",
    "# Load model\n",
    "model = resnet50_1d(num_classes=8)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# Load IQ data\n",
    "data = np.fromfile(ADV_IQ_FILE_PATH, dtype=\"float32\")\n",
    "assert data.size % 2 == 0, \"Expected even number of floats for I/Q pairs\"\n",
    "\n",
    "WINDOW_SIZE = data.size // 2\n",
    "print(f\"Detected IQ window length: {WINDOW_SIZE}\")\n",
    "\n",
    "original = np.fromfile(IQ_FILE_PATH, dtype=\"float32\")\n",
    "I_full = original[0::2]\n",
    "Q_full = original[1::2]\n",
    "\n",
    "# Get the same window that was used in PGD attack\n",
    "start = (START_INDEX + 1) * HOP_SIZE\n",
    "end = start + 10000  # or use perturbation.shape[1]\n",
    "\n",
    "I_orig = I_full[start:end]\n",
    "Q_orig = Q_full[start:end]\n",
    "original_np = np.vstack((I_orig, Q_orig))  # shape [2, 10000]\n",
    "\n",
    "\n",
    "# Load noise\n",
    "noise = np.fromfile(\"Apr16/pgd_noise_pluto0_target1.iq\", dtype=\"float32\")\n",
    "I_noise = noise[0::2]\n",
    "Q_noise = noise[1::2]\n",
    "perturbation = np.vstack((I_noise, Q_noise))  # shape [2, N]\n",
    "\n",
    "# Add them together\n",
    "adversarial_np = original_np + perturbation\n",
    "\n",
    "# Optional normalization (must match training/inference!)\n",
    "adversarial_np = adversarial_np / (np.linalg.norm(adversarial_np) + 1e-8)\n",
    "\n",
    "# Convert to tensor and run model\n",
    "tensor_input = torch.tensor(adversarial_np, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(tensor_input)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    pred = torch.argmax(probs, dim=1).item()\n",
    "    conf = probs.max(dim=1).values.item()\n",
    "\n",
    "print(f\"Reconstructed PGD prediction: {pred}, confidence: {conf:.4f}\")\n",
    "print(\"✅ Attack success!\" if pred == TARGET_LABEL else \"❌ Attack failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b150585-5ceb-4f5e-baee-534e352cd649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_inverse_channel(\n",
    "    x,\n",
    "    min_distance=1.0,\n",
    "    max_distance=2.0,\n",
    "    path_loss_exponent=2.0,\n",
    "    reference_distance=1.0,\n",
    "    noise_std=0.01,          # accepted but not used\n",
    "    apply_fading=True,       # accepted and mapped to apply_inverse_fading\n",
    "    apply_phase=True         # accepted but not used\n",
    "):\n",
    "    \"\"\"\n",
    "    Applies inverse path loss and (optional) fading compensation.\n",
    "    Ignores noise and phase parameters, included for call-site compatibility.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample a random target distance to invert\n",
    "    d = torch.empty(1, device=x.device).uniform_(min_distance, max_distance)\n",
    "    path_loss_scaling = (reference_distance / d) ** (path_loss_exponent / 2)\n",
    "    x_compensated = x / path_loss_scaling  # Invert path loss\n",
    "\n",
    "    if apply_fading:\n",
    "        # Real-valued Rayleigh fading inverse\n",
    "        fading_mag = torch.sqrt(torch.randn_like(x)**2 + torch.randn_like(x)**2)\n",
    "        fading_mag = torch.clamp(fading_mag, min=1e-3)\n",
    "        x_compensated = x_compensated / fading_mag\n",
    "\n",
    "    return x_compensated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1056133-5cab-4151-8b9c-b65e58f5fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_channel_effects(x, min_distance=1.0, max_distance=2.0, path_loss_exponent=2.0, reference_distance=1.0, noise_std=0.01, apply_fading=True, apply_phase=True):\n",
    "    # Sample a random distance between min and max\n",
    "    d = torch.empty(1, device=x.device).uniform_(min_distance, max_distance)\n",
    "\n",
    "    # Path loss scaling\n",
    "    scaling = (reference_distance / d) ** (path_loss_exponent/2)\n",
    "    x_transformed = x * scaling\n",
    "\n",
    "    # # Apply fading (Rayleigh fading)\n",
    "    # if apply_fading:\n",
    "    #     fading = torch.sqrt(torch.randn_like(x_transformed)**2 + torch.randn_like(x_transformed)**2)\n",
    "    #     x_transformed = x_transformed * fading\n",
    "\n",
    "    # # Add noise\n",
    "    # noise = torch.randn_like(x_transformed) * noise_std\n",
    "    # x_transformed = x_transformed + noise\n",
    "\n",
    "    # # Apply phase rotation (approximate for I/Q representation)\n",
    "    # if apply_phase:\n",
    "    #     phase = torch.empty(1, device=x.device).uniform_(0, 2 * np.pi)\n",
    "    #     x_transformed = x_transformed * torch.cos(phase)  # Simplified phase shift\n",
    "\n",
    "    return x_transformed\n",
    "\n",
    "\n",
    "# def transform_channel_effects(x, min_distance=1.0, max_distance=2.0, path_loss_exponent=2.0, reference_distance=1.0, noise_std=0.01, apply_fading=True, apply_phase=True):\n",
    "#     # Sample a random distance between min and max\n",
    "#     d = torch.empty(1, device=x.device).uniform_(min_distance, max_distance)\n",
    "\n",
    "#     # Path loss scaling\n",
    "#     scaling = (reference_distance / d) ** (path_loss_exponent /2)\n",
    "#     x_transformed = x * scaling\n",
    "\n",
    "#     # # Apply fading (Rayleigh fading)\n",
    "#     # if apply_fading:\n",
    "#     #     #fading = (np.sqrt(torch.randn_like(x_transformed)**2 + torch.randn_like(x_transformed)**2) )\n",
    "#     #     fading = (torch.randn_like(x_transformed) + torch.randn_like(x_transformed)) / np.sqrt(2)\n",
    "#     #     x_transformed = x_transformed * fading\n",
    "\n",
    "#     # # Add noise\n",
    "#     # noise = torch.randn_like(x_transformed) * noise_std\n",
    "#     # x_transformed = x_transformed + noise\n",
    "\n",
    "#     # Apply phase rotation (approximate for I/Q representation)\n",
    "#     # if apply_phase:\n",
    "#     #     phase = torch.empty(1, device=x.device).uniform_(0, 2 * np.pi)\n",
    "#     #     x_transformed = x_transformed * torch.cos(phase)  # Simplified phase shift\n",
    "\n",
    "#     return x_transformed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbeb192-ab23-4067-9a2c-357c4594840c",
   "metadata": {},
   "source": [
    "Create PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d97d619-6d3b-40e1-8b2a-4bc2b89511f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/1m_2m/Pluto_0_1m_run3.iq\n",
      "True label: 0, Target label: 1\n",
      "Saved EoT PGD noise to Apr16/mid_dist_eot_pluto10_to_target1_noise.iq\n",
      "\n",
      "Testing saved EoT noise from: Apr16/mid_dist_eot_pluto10_to_target1_noise.iq\n",
      "Full softmax probabilities:\n",
      "[[6.134845e-03 8.268639e-03 4.570728e-28 9.855965e-01 0.000000e+00\n",
      "  0.000000e+00 0.000000e+00 0.000000e+00]]\n",
      "Prediction on saved noise sample: 3, Confidence: 0.9856\n"
     ]
    }
   ],
   "source": [
    "def targeted_eot_pgd_attack(\n",
    "    model,\n",
    "    x,\n",
    "    y,\n",
    "    target_label,\n",
    "    eps=0.1,\n",
    "    alpha=0.01,\n",
    "    num_iter=80,\n",
    "    num_samples=10,\n",
    "    min_distance=1.0,\n",
    "    max_distance=2.0,\n",
    "    path_loss_exponent=2.0,\n",
    "    reference_distance=1.0,\n",
    "    noise_std=0.01,\n",
    "    apply_fading=True,\n",
    "    apply_phase=True\n",
    "):\n",
    "    x_adv = x.clone().detach().requires_grad_(True).to(DEVICE)\n",
    "    target = torch.full_like(y, target_label)\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        total_grad = torch.zeros_like(x_adv)\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "            x_t = transform_channel_effects(             #either add inverse or normal fading\n",
    "                x_adv,\n",
    "                min_distance=min_distance,\n",
    "                max_distance=max_distance,\n",
    "                path_loss_exponent=path_loss_exponent,\n",
    "                reference_distance=reference_distance,\n",
    "                noise_std=noise_std,\n",
    "                apply_fading=apply_fading,\n",
    "                apply_phase=apply_phase\n",
    "            )\n",
    "\n",
    "            logits = model(x_t)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "\n",
    "            grad = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "            total_grad += grad\n",
    "\n",
    "        avg_grad = total_grad / num_samples\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_adv -= alpha * avg_grad.sign()\n",
    "            x_adv = torch.max(torch.min(x_adv, x + eps), x - eps)\n",
    "            x_adv = x_adv.detach().clone().requires_grad_(True)\n",
    "\n",
    "    return x_adv\n",
    "\n",
    "def generate_eot_pgd_noise():\n",
    "    print(f\"Loading data from: {IQ_FILE_PATH}\")\n",
    "    label = int(os.path.basename(IQ_FILE_PATH).split(\"_\")[1])\n",
    "    print(f\"True label: {label}, Target label: {TARGET_LABEL}\")\n",
    "\n",
    "    # Load IQ data\n",
    "    data = np.fromfile(IQ_FILE_PATH, dtype=\"float32\")\n",
    "    real = data[0::2]\n",
    "    imag = data[1::2]\n",
    "    start = (START_INDEX + 1) * HOP_SIZE\n",
    "    end = start + WINDOW_SIZE\n",
    "    i_window = real[start:end]\n",
    "    q_window = imag[start:end]\n",
    "    combined = np.vstack((i_window, q_window))  # [2, N]\n",
    "\n",
    "    # Format into dataset\n",
    "    test_dataset = IQDataset([combined], [label])\n",
    "    data_tensor, label_tensor = test_dataset[0]\n",
    "    data_tensor = data_tensor.unsqueeze(0).to(DEVICE)\n",
    "    label_tensor = label_tensor.unsqueeze(0).to(DEVICE)\n",
    "    min_distance=1.0\n",
    "    max_distance=2.0\n",
    "    EPSILON = 0.1\n",
    "    ALPHA = 0.02\n",
    "    ATTACK_ITERATIONS = 40\n",
    "    if min_distance >= 5.0:\n",
    "        EPSILON = 0.6\n",
    "        ALPHA = 0.021\n",
    "        ATTACK_ITERATIONS = 100\n",
    "\n",
    "    # EoT PGD attack\n",
    "    #x_adv = data_tensor.clone().detach().to(DEVICE)\n",
    "\n",
    "    x_adv = targeted_eot_pgd_attack(\n",
    "        model=model,\n",
    "        x=data_tensor,\n",
    "        y=label_tensor,\n",
    "        target_label=TARGET_LABEL,\n",
    "        eps=EPSILON,\n",
    "        alpha=ALPHA,\n",
    "        num_iter=ATTACK_ITERATIONS,\n",
    "        num_samples=10,\n",
    "        min_distance=min_distance,\n",
    "        max_distance=max_distance,\n",
    "        noise_std=0.001 \n",
    "    )\n",
    "\n",
    "    # Save perturbation only\n",
    "    original_np = data_tensor.squeeze().cpu().numpy()\n",
    "    adv_np = x_adv.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    I_diff = adv_np[0] - original_np[0]\n",
    "    Q_diff = adv_np[1] - original_np[1]\n",
    "\n",
    "    interleaved = np.empty(I_diff.size + Q_diff.size, dtype=np.float32)\n",
    "    interleaved[0::2] = I_diff\n",
    "    interleaved[1::2] = Q_diff\n",
    "\n",
    "    save_path = \"Apr16/mid_dist_eot_pluto10_to_target1_noise.iq\"\n",
    "    interleaved.tofile(save_path)\n",
    "    print(f\"Saved EoT PGD noise to {save_path}\")\n",
    "\n",
    "    # --- Evaluate by re-applying noise to original signal ---\n",
    "    print(f\"\\nTesting saved EoT noise from: {save_path}\")\n",
    "    noise = np.fromfile(save_path, dtype=np.float32)\n",
    "    I_noise = noise[0::2]\n",
    "    Q_noise = noise[1::2]\n",
    "\n",
    "    perturbed = np.vstack((i_window + I_noise, q_window + Q_noise))\n",
    "    test_dataset = IQDataset([perturbed], [label])\n",
    "    data_tensor_adv, _ = test_dataset[0]\n",
    "    data_tensor_adv = data_tensor_adv.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits_adv = model(data_tensor_adv)\n",
    "        probs_adv = F.softmax(logits_adv, dim=1)\n",
    "        print(f\"Full softmax probabilities:\\n{probs_adv.cpu().numpy()}\")\n",
    "\n",
    "        adv_pred = torch.argmax(probs_adv, dim=1)\n",
    "        adv_conf = probs_adv.max(dim=1).values\n",
    "\n",
    "    print(f\"Prediction on saved noise sample: {adv_pred.item()}, Confidence: {adv_conf.item():.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_eot_pgd_noise()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0650f31f-0db6-49e2-bf87-7aac21059820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: Apr16/mid_dist_eot_pluto0_to_target1_noise.iq\n",
      "[mid_dist_eot_pluto0_to_target1_noise.iq] Prediction: 0, Confidence: 0.9991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4026202/892844258.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    }
   ],
   "source": [
    "TRUE_IQ_FILE_PATH = \"Apr16/mid_dist_eot_pluto0_to_target1_noise.iq\"\n",
    "WINDOW_SIZE = 10000\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = resnet50_1d(num_classes=8)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# Get filename\n",
    "fname = os.path.basename(TRUE_IQ_FILE_PATH)\n",
    "print(f\"\\nProcessing file: {TRUE_IQ_FILE_PATH}\")\n",
    "\n",
    "# Manually assign label since filename doesn't follow Pluto_# format\n",
    "target_label = 0  # or whatever the expected true label is\n",
    "\n",
    "# Load IQ data\n",
    "data = np.fromfile(TRUE_IQ_FILE_PATH, dtype=\"float32\")\n",
    "real_part = data[0::2]\n",
    "imag_part = data[1::2]\n",
    "\n",
    "# Check file length\n",
    "start = 0\n",
    "end = start + WINDOW_SIZE\n",
    "if end > len(real_part):\n",
    "    raise ValueError(f\"Not enough samples in file: required {end}, got {len(real_part)}\")\n",
    "\n",
    "# Extract 1 window\n",
    "i_window = real_part[start:end]\n",
    "q_window = imag_part[start:end]\n",
    "combined = np.vstack((i_window, q_window))  # shape: [2, WINDOW_SIZE]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "test_dataset = IQDataset([combined], [target_label])\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Evaluate\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        pred = torch.argmax(probs, dim=1)\n",
    "        conf = probs.max(dim=1).values\n",
    "        print(f\"[{fname}] Prediction: {pred.item()}, Confidence: {conf.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14fbb63-ff96-498f-9108-596303855c21",
   "metadata": {},
   "source": [
    "TEST all the files in base dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "975f6a7b-43b6-4227-8097-f36de55cefdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22101/3514134200.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11/pluto0/pluto0_2m_adv1m_concateotlow.iq\n",
      "[pluto0_2m_adv1m_concateotlow.iq] Prediction: 1, Confidence: 0.9998\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11/pluto0/pluto0_2m_adv2m_eotlow.iq\n",
      "[pluto0_2m_adv2m_eotlow.iq] Prediction: 0, Confidence: 0.9461\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11/pluto0/pluto0_2m_adv1m_concateotmid.iq\n",
      "[pluto0_2m_adv1m_concateotmid.iq] Prediction: 1, Confidence: 0.9994\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11/pluto0/pluto0_2m_adv1m_eotlow.iq\n",
      "[pluto0_2m_adv1m_eotlow.iq] Prediction: 4, Confidence: 0.9980\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11/pluto0/pluto0_2m_adv2m_noise.iq\n",
      "[pluto0_2m_adv2m_noise.iq] Prediction: 0, Confidence: 0.9961\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11/pluto0/pluto0_2m_adv1m_eotmid.iq\n",
      "[pluto0_2m_adv1m_eotmid.iq] Prediction: 1, Confidence: 0.8037\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11/pluto0/pluto0_2m_adv1m_noise.iq\n",
      "[pluto0_2m_adv1m_noise.iq] Prediction: 1, Confidence: 0.8519\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11/pluto10/pluto10_2m_adv1m_concateotlow.iq\n",
      "[pluto10_2m_adv1m_concateotlow.iq] Prediction: 0, Confidence: 1.0000\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11/pluto10/pluto10_2m_adv1m_eotlow.iq\n",
      "[pluto10_2m_adv1m_eotlow.iq] Prediction: 2, Confidence: 0.9848\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11/pluto10/pluto10_2m_adv1m_eotmid.iq\n",
      "[pluto10_2m_adv1m_eotmid.iq] Prediction: 2, Confidence: 1.0000\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11/pluto10/pluto10_2m_adv1m_noise.iq\n",
      "[pluto10_2m_adv1m_noise.iq] Prediction: 2, Confidence: 0.9934\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11/pluto10/pluto10_2m_adv1m_concateotmid.iq\n",
      "[pluto10_2m_adv1m_concateotmid.iq] Prediction: 2, Confidence: 0.9372\n"
     ]
    }
   ],
   "source": [
    "TRUE_IQ_FILE_PATH = \"Apr9/mid_dist_eot_pluto10_to_target1_noise.iq\"\n",
    "WINDOW_SIZE = 10000\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = resnet50_1d(num_classes=8)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "BASE_DIR = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/Apr11\"\n",
    "TARGET_DIRS = [\"pluto0\", \"pluto10\"]\n",
    "iq_file_paths = []\n",
    "\n",
    "for subdir in TARGET_DIRS:\n",
    "    dir_path = os.path.join(BASE_DIR, subdir)\n",
    "    for file in os.listdir(dir_path):\n",
    "        if file.endswith(\".iq\"):\n",
    "            iq_file_paths.append(os.path.join(dir_path, file))\n",
    "\n",
    "# Loop through each file and test\n",
    "for file_path in iq_file_paths:\n",
    "    fname = os.path.basename(file_path)\n",
    "    print(f\"\\nProcessing file: {file_path}\")\n",
    "\n",
    "    # Assign label based on directory (adjust if your labels differ)\n",
    "    if \"pluto0\" in file_path:\n",
    "        target_label = 0\n",
    "    elif \"pluto10\" in file_path:\n",
    "        target_label = 1\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown label source in path: {file_path}\")\n",
    "\n",
    "    # Load IQ data\n",
    "    data = np.fromfile(file_path, dtype=\"float32\")\n",
    "    real_part = data[0::2]\n",
    "    imag_part = data[1::2]\n",
    "\n",
    "    # Check file length\n",
    "    start = 0\n",
    "    end = start + WINDOW_SIZE\n",
    "    if end > len(real_part):\n",
    "        print(f\"[{fname}] Skipped: Not enough samples (required {end}, got {len(real_part)})\")\n",
    "        continue\n",
    "\n",
    "    # Extract 1 window\n",
    "    i_window = real_part[start:end]\n",
    "    q_window = imag_part[start:end]\n",
    "    combined = np.vstack((i_window, q_window))  # shape: [2, WINDOW_SIZE]\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    test_dataset = IQDataset([combined], [target_label])\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Evaluate\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images = images.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            pred = torch.argmax(probs, dim=1)\n",
    "            conf = probs.max(dim=1).values\n",
    "            print(f\"[{fname}] Prediction: {pred.item()}, Confidence: {conf.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1238695-3b44-405f-8286-1b5183d148fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_inverse_channel_compensation(x, target_distance=1.5, path_loss_exponent=2.0, reference_distance=1.0, apply_inverse_fading=True):\n",
    "\n",
    "    # calculate scaling power like before\n",
    "    path_loss_scaling = (reference_distance / target_distance) ** (path_loss_exponent / 2)\n",
    "    x_compensated = x / path_loss_scaling  # INVERSE of attenuation\n",
    "\n",
    "    # Estimate and invert fading\n",
    "    if apply_inverse_fading:\n",
    "        # Generate a sample fading coefficient (complex Rayleigh)\n",
    "        fading = (torch.randn_like(x) + 1j * torch.randn_like(x)) / np.sqrt(2)\n",
    "        x_compensated = x_compensated / fading  # INVERSE of fading\n",
    "\n",
    "    return x_compensated\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
