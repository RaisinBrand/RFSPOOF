{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d456f7b9-3caa-43f9-9654-4b512a018153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F  \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a5a9323-e14b-429e-a9a8-821efcc8e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/models\") #probably keep this still\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#MODEL_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/justin_model_slicing_norm_LR1_smallHop_12_largerInput.pth\" #probably keep this still\n",
    "#IQ_FILE_PATH = \"/data2/brandan/RFSPOOF/brandan/1m_targeted/run0.iq\" \n",
    "\n",
    "MODEL_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e8f3b9c-d54b-4d0f-97ea-8bcf174eeb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "file_list = [\n",
    "    \"brandan_2/pluto0_1m_adv_2m_run0.iq\",\n",
    "    \"brandan_2/pluto0_1m_adv_2m_run1.iq\",\n",
    "    \"brandan_2/pluto0_1mLeft_adv_1mRight_run0.iq\",\n",
    "    \"brandan_2/pluto0_1mLeft_adv_1mRight_run1.iq\",\n",
    "    \"brandan_2/pluto0_2m_adv_1m_run0.iq\",\n",
    "    \"brandan_2/pluto0_2m_adv_1m_run1.iq\",\n",
    "    \"brandan_2/pluto0_2m_adv_2m_run0.iq\",\n",
    "    \"brandan_2/pluto0_2m_adv_2m_run1.iq\",\n",
    "    \"brandan_2/pluto0_2mLeft_adv_2mRight_run0.iq\",\n",
    "    \"brandan_2/pluto0_2mLeft_adv_2mRight_run1.iq\"\n",
    "]\n",
    "'''\n",
    "\n",
    "file_list = [\n",
    "    \"brandan_4_1/2m_adv2m_eot.iq\",\n",
    "    \"brandan_4_1/2m_adv2m.iq\",\n",
    "    \"brandan_4_1/2m_adv3m_eot.iq\",\n",
    "    \"brandan_4_1/2m_adv3m.iq\",\n",
    "    \"brandan_4_2/2m_adv4m_eot.iq\",\n",
    "    \"brandan_4_2/2m_adv4m.iq\",\n",
    "    \"brandan_4_2/2m_advside2.5m_eot.iq\",\n",
    "    \"brandan_4_2/2m_advside2.5m.iq\"\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483dced1-4b87-48f4-af9b-a266d904e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attempt2 import resnet50_1d  \n",
    "num_classes = 8 \n",
    "\n",
    "model = resnet50_1d(num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "MODEL_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/justin_model_slicing_norm_LR1_smallHop_12.pth\" #probably keep this still\n",
    "#print(f\"Loading trained model weights from: {MODEL_PATH}\")\n",
    "state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd1ab330-a0c2-475f-917a-35e7c3f874dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iq_data(file_path, start_idx=0, max_samples=4096*2):\n",
    "    total_samples = max_samples * 2 \n",
    "    with open(file_path, \"rb\") as f:\n",
    "        f.seek(start_idx * 4 * 2)  \n",
    "        raw_data = np.fromfile(f, dtype=\"float32\", count=total_samples)\n",
    "\n",
    "    if raw_data.shape[0] < total_samples:\n",
    "        raise ValueError(f\"Not enough data in {file_path}. Requested {total_samples}, got {raw_data.shape[0]}.\")\n",
    "\n",
    "    #  Extract I/Q channels\n",
    "    I = raw_data[0::2]  \n",
    "    Q = raw_data[1::2]  \n",
    "\n",
    "    iq_data = np.stack([I, Q], axis=0)\n",
    "\n",
    "    iq_data = np.expand_dims(iq_data, axis=0)\n",
    "\n",
    "    data_tensor = torch.from_numpy(iq_data).float()\n",
    "\n",
    "    label_tensor = torch.tensor([0], dtype=torch.long)\n",
    "\n",
    "    return data_tensor, label_tensor #loading IQ samples i got from chatgpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c8911a1-3661-40df-8e1a-c1e8eabff13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 42697200, Total chunks: 5212\n",
      "avg confidence = tensor([0.9559], device='cuda:0'), amt of 3 is 4832\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "this is code that tests each batch of 8912 samples and aggregates the accuracy\n",
    "'''\n",
    "individual_path = \"brandan/1m_targeted/run0.iq\"\n",
    "file_size = os.path.getsize(individual_path) \n",
    "total_samples = file_size // (4 * 2)  \n",
    "max_samples = 4096 * 2  \n",
    "total_chunks = total_samples // max_samples \n",
    "\n",
    "print(f\"Total samples: {total_samples}, Total chunks: {total_chunks}\")\n",
    "\n",
    "\n",
    "start_idx = max(0, total_chunks - 10)  \n",
    "\n",
    "\n",
    "count3 = 0\n",
    "avg_conf = 0\n",
    "for idx in range(0, total_chunks):\n",
    "    data, labels = load_iq_data(individual_path, start_idx=idx * max_samples)\n",
    "    data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        raw_output = model(data)\n",
    "        probabilities = F.softmax(raw_output, dim=1) #softmax prob to 0-1 prob\n",
    "        prediction = torch.argmax(probabilities, dim=1)  #take max prediction and confidence\n",
    "        confidence = probabilities.max(dim=1).values\n",
    "        \n",
    "        if prediction == 3:\n",
    "            avg_conf += confidence\n",
    "            count3+=1\n",
    "            \n",
    "    \n",
    "    #print(f\"prediction: {prediction.cpu().numpy()}, confidence = {confidence.cpu().item():.4f}, \")\n",
    "\n",
    "print(f\"avg confidence = {avg_conf/count3}, amt of chunks classified as 3 is {count3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf7c4646-f044-44cf-b3eb-f992cac6493e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 41928120, Total chunks: 5118\n",
      "File path: brandan_4_1/2m_adv2m_eot.iq, avg confidence = 0.9842, std deviation = 0.0503, amt of 3 is 5031\n",
      "Total samples: 41669040, Total chunks: 5086\n",
      "File path: brandan_4_1/2m_adv2m.iq, avg confidence = 0.9871, std deviation = 0.0484, amt of 3 is 4958\n",
      "Total samples: 41746560, Total chunks: 5096\n",
      "File path: brandan_4_1/2m_adv3m_eot.iq, avg confidence = 0.9817, std deviation = 0.0532, amt of 3 is 5006\n",
      "Total samples: 41654760, Total chunks: 5084\n",
      "File path: brandan_4_1/2m_adv3m.iq, avg confidence = 0.9684, std deviation = 0.0781, amt of 3 is 4807\n",
      "Total samples: 41491560, Total chunks: 5064\n",
      "File path: brandan_4_2/2m_adv4m_eot.iq, avg confidence = 0.9354, std deviation = 0.1043, amt of 3 is 4572\n",
      "Total samples: 41503800, Total chunks: 5066\n",
      "File path: brandan_4_2/2m_adv4m.iq, avg confidence = 0.9516, std deviation = 0.0896, amt of 3 is 4694\n",
      "Total samples: 41750640, Total chunks: 5096\n",
      "File path: brandan_4_2/2m_advside2.5m_eot.iq, avg confidence = 0.8943, std deviation = 0.1292, amt of 3 is 3987\n",
      "Total samples: 41897520, Total chunks: 5114\n",
      "File path: brandan_4_2/2m_advside2.5m.iq, avg confidence = 0.9062, std deviation = 0.1222, amt of 3 is 4071\n"
     ]
    }
   ],
   "source": [
    "for path in file_list:\n",
    "    file_size = os.path.getsize(path) \n",
    "    total_samples = file_size // (4 * 2)  \n",
    "    max_samples = 4096 * 2  \n",
    "    total_chunks = total_samples // max_samples \n",
    "\n",
    "    print(f\"Total samples: {total_samples}, Total chunks: {total_chunks}\")\n",
    "\n",
    "    count3 = 0\n",
    "    conf_values = []  # Store confidence values for class 3\n",
    "\n",
    "    for idx in range(0, total_chunks):\n",
    "        data, labels = load_iq_data(path, start_idx=idx * max_samples)\n",
    "        data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            raw_output = model(data)\n",
    "            probabilities = F.softmax(raw_output, dim=1)  # Convert logits to probabilities\n",
    "            prediction = torch.argmax(probabilities, dim=1)  # Get predicted class\n",
    "            confidence = probabilities.max(dim=1).values  # Get confidence score\n",
    "\n",
    "            mask = prediction == 3  # Mask for class 3\n",
    "            if mask.any():\n",
    "                count3 += mask.sum().item()\n",
    "                conf_values.extend(confidence[mask].cpu().tolist())  # Convert to list\n",
    "\n",
    "    if count3 > 0:\n",
    "        avg_conf = sum(conf_values) / count3  # Compute mean\n",
    "        std_dev = torch.std(torch.tensor(conf_values), unbiased=True).item() if len(conf_values) > 1 else 0  # Compute std deviation\n",
    "    else:\n",
    "        avg_conf = 0\n",
    "        std_dev = 0\n",
    "\n",
    "    print(f\"File path: {path}, avg confidence = {avg_conf:.4f}, std deviation = {std_dev:.4f}, amt of 3 is {count3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a670fa-df38-48d9-9d7d-84d4ee87ba92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthis is code that tests all the first 8912 samples of data\\nfor IQ_FILE_PATH in file_list:\\n    # Load data and move to device\\n    data, labels = load_iq_data(IQ_FILE_PATH)\\n    data, labels = data.to(DEVICE), labels.to(DEVICE)\\n    \\n    print(f\"The File: {IQ_FILE_PATH}\")\\n    #print(\"Original data shape:\", data.shape)\\n    \\n    # Run the model on the data\\n    with torch.no_grad():\\n        logits = model(data)                # Raw model output\\n        probs = F.softmax(logits, dim=1)      # Convert to probabilities\\n        original_pred = torch.argmax(probs, dim=1)  # Predicted class\\n        confidence = probs.max(dim=1).values       # Confidence score\\n    \\n    # Print the results\\n    print(f\"Prediction: {original_pred.cpu().numpy()}, Confidence: {confidence.cpu().item():.4f}\\n\")\\n    '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "this is code that tests all the first 8912 samples of data\n",
    "for IQ_FILE_PATH in file_list:\n",
    "    # Load data and move to device\n",
    "    data, labels = load_iq_data(IQ_FILE_PATH)\n",
    "    data, labels = data.to(DEVICE), labels.to(DEVICE)\n",
    "    \n",
    "    print(f\"The File: {IQ_FILE_PATH}\")\n",
    "    #print(\"Original data shape:\", data.shape)\n",
    "    \n",
    "    # Run the model on the data\n",
    "    with torch.no_grad():\n",
    "        logits = model(data)                # Raw model output\n",
    "        probs = F.softmax(logits, dim=1)      # Convert to probabilities\n",
    "        original_pred = torch.argmax(probs, dim=1)  # Predicted class\n",
    "        confidence = probs.max(dim=1).values       # Confidence score\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Prediction: {original_pred.cpu().numpy()}, Confidence: {confidence.cpu().item():.4f}\\n\")\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41db377f-9d62-4516-94bc-93888d12d645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adv_path = \"/data2/brandan/RFSPOOF/brandan/1m_targeted/run0.iq\" \\nChannel_path = \"/data2/brandan/RFSPOOF/brandan/adversary_noise/run0.iq\" \\n\\nAdv_data, Adv_labels = load_iq_data(Adv_path)\\nAdv_data, Adv_labels = data.to(DEVICE), labels.to(DEVICE)\\n\\nChannel_data, Channel_labels = load_iq_data(Channel_path)\\nChannel_data, Channel_labels = data.to(DEVICE), labels.to(DEVICE)\\nAdv_data_np = Adv_data.cpu().detach().numpy()\\nChannel_data_np = Channel_data.cpu().detach().numpy()\\n\\nI_Channel = Adv_data_np[0, 0, :]  \\nQ_Channel = Adv_data_np[0, 1, :]  \\n\\nI_Adv = Channel_data_np[0, 0, :] \\nQ_Adv = Channel_data_np[0, 1, :] \\n\\ntime = np.arange(I_Channel.shape[0])\\n\\ndownsample_factor = 100  # Adjust as needed\\ntime = time[::downsample_factor]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Adv_path = \"/data2/brandan/RFSPOOF/brandan/1m_targeted/run0.iq\" \n",
    "Channel_path = \"/data2/brandan/RFSPOOF/brandan/adversary_noise/run0.iq\" \n",
    "\n",
    "Adv_data, Adv_labels = load_iq_data(Adv_path)\n",
    "Adv_data, Adv_labels = data.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "Channel_data, Channel_labels = load_iq_data(Channel_path)\n",
    "Channel_data, Channel_labels = data.to(DEVICE), labels.to(DEVICE)\\\n",
    "\n",
    "Adv_data_np = Adv_data.cpu().detach().numpy()\n",
    "Channel_data_np = Channel_data.cpu().detach().numpy()\n",
    "\n",
    "I_Channel = Adv_data_np[0, 0, :]  \n",
    "Q_Channel = Adv_data_np[0, 1, :]  \n",
    "\n",
    "I_Adv = Channel_data_np[0, 0, :] \n",
    "Q_Adv = Channel_data_np[0, 1, :] \n",
    "\n",
    "time = np.arange(I_Channel.shape[0])\n",
    "\n",
    "downsample_factor = 100  # Adjust as needed\n",
    "time = time[::downsample_factor]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df952026-3cb6-4c38-b473-e14ea49a80b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.subplot(3, 1, 1)\\nplt.plot(time, I_Adv, label=\"Original I\", alpha=0.7)\\nplt.plot(time, I_Channel, label=\"Adversarial I\", linestyle=\"dashed\", alpha=0.7)\\nplt.title(\"Time-Domain Signal: Original vs. Adversarial (I Channel)\")\\nplt.xlabel(\"Sample Index\")\\nplt.ylabel(\"Amplitude\")\\nplt.legend()'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''plt.subplot(3, 1, 1)\n",
    "plt.plot(time, I_Adv, label=\"Original I\", alpha=0.7)\n",
    "plt.plot(time, I_Channel, label=\"Adversarial I\", linestyle=\"dashed\", alpha=0.7)\n",
    "plt.title(\"Time-Domain Signal: Original vs. Adversarial (I Channel)\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9acc1-3d16-44ac-a707-0bc59acb475c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b11e31-7d47-4088-b870-455ad81852ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: brandan_2/pluto0_1m_adv_2m_run0.iq\n",
      "Processing: brandan_2/pluto0_1m_adv_2m_run1.iq\n",
      "Processing: brandan_2/pluto0_1mLeft_adv_1mRight_run0.iq\n",
      "Processing: brandan_2/pluto0_1mLeft_adv_1mRight_run1.iq\n",
      "Processing: brandan_2/pluto0_2m_adv_1m_run0.iq\n",
      "Processing: brandan_2/pluto0_2m_adv_1m_run1.iq\n",
      "Processing: brandan_2/pluto0_2m_adv_2m_run0.iq\n",
      "Processing: brandan_2/pluto0_2m_adv_2m_run1.iq\n",
      "Processing: brandan_2/pluto0_2mLeft_adv_2mRight_run0.iq\n",
      "Processing: brandan_2/pluto0_2mLeft_adv_2mRight_run1.iq\n",
      "Final Test Accuracy: 16.57%\n",
      "File: brandan_2/pluto0_1m_adv_2m_run0.iq\n",
      "Predicted Class: 4, Confidence: 0.3557\n",
      "\n",
      "File: brandan_2/pluto0_1m_adv_2m_run1.iq\n",
      "Predicted Class: 4, Confidence: 0.5250\n",
      "\n",
      "File: brandan_2/pluto0_1mLeft_adv_1mRight_run0.iq\n",
      "Predicted Class: 4, Confidence: 0.3290\n",
      "\n",
      "File: brandan_2/pluto0_1mLeft_adv_1mRight_run1.iq\n",
      "Predicted Class: 4, Confidence: 0.3636\n",
      "\n",
      "File: brandan_2/pluto0_2m_adv_1m_run0.iq\n",
      "Predicted Class: 4, Confidence: 0.3741\n",
      "\n",
      "File: brandan_2/pluto0_2m_adv_1m_run1.iq\n",
      "Predicted Class: 7, Confidence: 0.3822\n",
      "\n",
      "File: brandan_2/pluto0_2m_adv_2m_run0.iq\n",
      "Predicted Class: 7, Confidence: 0.3051\n",
      "\n",
      "File: brandan_2/pluto0_2m_adv_2m_run1.iq\n",
      "Predicted Class: 4, Confidence: 0.3210\n",
      "\n",
      "File: brandan_2/pluto0_2mLeft_adv_2mRight_run0.iq\n",
      "Predicted Class: 7, Confidence: 0.6127\n",
      "\n",
      "File: brandan_2/pluto0_2mLeft_adv_2mRight_run1.iq\n",
      "Predicted Class: 5, Confidence: 0.2981\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "this is code that loads data the way justin had it before\n",
    "\n",
    "def load_iq_data(file_path):\n",
    "    \"\"\"\n",
    "    Loads an IQ binary file and extracts real/imaginary components.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the `.iq` file.\n",
    "\n",
    "    Returns:\n",
    "        np.array: Data in shape (2, sequence_length).\n",
    "    \"\"\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        raw_data = np.fromfile(f, dtype=\"float32\")\n",
    "\n",
    "    size_data = len(raw_data)\n",
    "    size_half = size_data // 2\n",
    "    real_part = raw_data[:size_half]  # I (In-phase)\n",
    "    imag_part = raw_data[size_half:]  # Q (Quadrature)\n",
    "\n",
    "    return real_part, imag_part\n",
    "\n",
    "# **Dataset Class (Using Training Processing)**\n",
    "class IQDataset(Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        self.file_list = file_list\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.load_files()\n",
    "\n",
    "    def load_files(self):\n",
    "        \"\"\"\n",
    "        Loads all IQ files and slices them into overlapping test segments.\n",
    "        \"\"\"\n",
    "        for i, file_path in enumerate(self.file_list):\n",
    "            print(f\"Processing: {file_path}\")\n",
    "            \n",
    "            # Load IQ data\n",
    "            real_part, imag_part = load_iq_data(file_path)\n",
    "\n",
    "            # **Apply the same slicing logic as during training**\n",
    "            for x in range(4800, 6000):  # Matching test range in training\n",
    "                combined_data = np.vstack((\n",
    "                    real_part[(x+1)*500:(x+1)*500+10000], \n",
    "                    imag_part[(x+1)*500:(x+1)*500+10000]\n",
    "                ))\n",
    "                self.data.append(combined_data)\n",
    "                self.labels.append(i)  # Assign label based on file index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        sample = torch.from_numpy(sample).float()\n",
    "        # Normalize (Same as Training)\n",
    "        magnitude = torch.sqrt(torch.sum(sample**2, dim=1, keepdim=True))\n",
    "        sample = sample / (magnitude + 1e-10)  # Avoid division by zero\n",
    "\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return sample, label_tensor\n",
    "\n",
    "# **Load dataset & DataLoader**\n",
    "test_dataset = IQDataset(file_list)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# **Run Inference on Test Data**\n",
    "correct = 0\n",
    "total = 0\n",
    "all_confidences = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        # Run model inference\n",
    "        outputs = model(inputs)\n",
    "        probs = F.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "        predicted = torch.argmax(probs, dim=1)  # Predicted class\n",
    "        confidence = probs.max(dim=1).values  # Confidence score\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store predictions & confidence scores\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_confidences.extend(confidence.cpu().numpy())\n",
    "\n",
    "# Compute final accuracy\n",
    "accuracy = correct / total * 100\n",
    "print(f'Final Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# **Print sample predictions & confidence scores**\n",
    "for i, file in enumerate(file_list):\n",
    "    print(f\"File: {file}\")\n",
    "    print(f\"Predicted Class: {all_predictions[i]}, Confidence: {all_confidences[i]:.4f}\\n\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6742d-3d3a-42eb-b1e1-6667ab89a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "File Path,Total Samples,Total Chunks,Avg Confidence,Std Deviation,Amount of 3\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
