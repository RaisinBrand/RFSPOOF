{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "793b3b4e-91af-423b-951f-128cf7d04d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F  \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f86f89d2-e60b-4dbe-b1ae-5721ccee3162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eot', 'noise', 'concat']\n",
      "['Pluto_0_eot_7m.iq', 'Pluto_0_eot_5m.iq', 'Pluto_0_eot_3m.iq']\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/models\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model_retrained.pth\"\n",
    "Pluto_0_dir = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto0_adv\"\n",
    "Pluto_10_dir = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto10_adv\"\n",
    "Pluto_0_eot = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto0_adv/eot\"\n",
    "\n",
    "\n",
    "path = Pluto_0_dir\n",
    "directories = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "print(directories)\n",
    "\n",
    "path = Pluto_0_eot\n",
    "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc46ba37-2412-4c43-b997-5887e9002d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model weights from: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model_retrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_115953/2189494409.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet1D(\n",
       "  (conv1): Conv1d(2, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck1D(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck1D(\n",
       "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Bottleneck1D(\n",
       "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck1D(\n",
       "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck1D(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Bottleneck1D(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Bottleneck1D(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck1D(\n",
       "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck1D(\n",
       "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Bottleneck1D(\n",
       "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=2048, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from attempt2 import resnet50_1d  # Directly import from attempt2.py\n",
    "num_classes = 8  # Change this if your model was trained with a different number of classes\n",
    "\n",
    "# Initialize the model architecture\n",
    "model = resnet50_1d(num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "# Load trained weights\n",
    "print(f\"Loading trained model weights from: {MODEL_PATH}\")\n",
    "state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712faa34-ee2b-4841-a6b2-a21a32b483df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IQDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        sample = torch.from_numpy(sample).float()\n",
    "        # Normalize data\n",
    "        magnitude = torch.sqrt(torch.sum(sample**2, dim=1, keepdim=True))\n",
    "        sample = sample / magnitude\n",
    "\n",
    "        label_tensors = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return sample, label_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "059385b0-6cfe-4f66-a30d-0e47cf6ecc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_115953/2281034695.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto0_adv/eot/Pluto_0_eot_7m.iq\n",
      "[Pluto_0_eot_7m.iq] Prediction: 1, Confidence: 0.9996\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto0_adv/eot/Pluto_0_eot_5m.iq\n",
      "[Pluto_0_eot_5m.iq] Prediction: 1, Confidence: 0.9955\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto0_adv/eot/Pluto_0_eot_3m.iq\n",
      "[Pluto_0_eot_3m.iq] Prediction: 1, Confidence: 0.8572\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto0_adv/noise/Pluto_0_noise_5m.iq\n",
      "[Pluto_0_noise_5m.iq] Prediction: 0, Confidence: 0.9792\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto0_adv/noise/Pluto_0_noise_7m.iq\n",
      "[Pluto_0_noise_7m.iq] Prediction: 0, Confidence: 1.0000\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto0_adv/noise/Pluto_0_noise_3m.iq\n",
      "[Pluto_0_noise_3m.iq] Prediction: 3, Confidence: 0.8469\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto0_adv/concat/Pluto_0_concat_3m.iq\n",
      "[Pluto_0_concat_3m.iq] Prediction: 2, Confidence: 0.8589\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto0_adv/concat/Pluto_0_concat_5m.iq\n",
      "[Pluto_0_concat_5m.iq] Prediction: 2, Confidence: 0.9818\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto0_adv/concat/Pluto_0_concat_7m.iq\n",
      "[Pluto_0_concat_7m.iq] Prediction: 2, Confidence: 0.9991\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto10_adv/eot/Pluto_10_7m_eot.iq\n",
      "[Pluto_10_7m_eot.iq] Prediction: 2, Confidence: 0.9985\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto10_adv/eot/Pluto_10_5m_eot.iq\n",
      "[Pluto_10_5m_eot.iq] Prediction: 2, Confidence: 1.0000\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto10_adv/eot/Pluto_10_3m_eot.iq\n",
      "[Pluto_10_3m_eot.iq] Prediction: 4, Confidence: 0.9493\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto10_adv/noise/Pluto_10_3m_noise.iq\n",
      "[Pluto_10_3m_noise.iq] Prediction: 4, Confidence: 1.0000\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto10_adv/noise/Pluto_10_5m_noise.iq\n",
      "[Pluto_10_5m_noise.iq] Prediction: 2, Confidence: 0.5659\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto10_adv/noise/Pluto_10_7m_noise.iq\n",
      "[Pluto_10_7m_noise.iq] Prediction: 7, Confidence: 0.8966\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto10_adv/concat/Pluto_10_5m_concat.iq\n",
      "[Pluto_10_5m_concat.iq] Prediction: 2, Confidence: 0.9999\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto10_adv/concat/Pluto_10_7m_concat.iq\n",
      "[Pluto_10_7m_concat.iq] Prediction: 1, Confidence: 0.9615\n",
      "\n",
      "Processing file: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto10_adv/concat/Pluto_10_3m_concat.iq\n",
      "[Pluto_10_3m_concat.iq] Prediction: 2, Confidence: 0.7194\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZE = 10000\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model_retrained.pth\"\n",
    "BASE_DIRS = [\n",
    "    \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto0_adv\",\n",
    "    \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/justin/april_4/pluto10_adv\",\n",
    "]\n",
    "TARGET_LABEL = 1\n",
    "\n",
    "# Load model\n",
    "model = resnet50_1d(num_classes=8)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# Process each file\n",
    "for base_dir in BASE_DIRS:\n",
    "    for subdir in [\"eot\", \"noise\", \"concat\"]:\n",
    "        path = os.path.join(base_dir, subdir)\n",
    "        iq_files = [f for f in os.listdir(path) if f.endswith(\".iq\")]\n",
    "        for file in iq_files:\n",
    "            full_path = os.path.join(path, file)\n",
    "            #print(f\"\\nProcessing file: {full_path}\")\n",
    "            \n",
    "            # Load IQ data\n",
    "            data = np.fromfile(full_path, dtype=\"float32\")\n",
    "            real_part = data[0::2]\n",
    "            imag_part = data[1::2]\n",
    "\n",
    "            if len(real_part) < WINDOW_SIZE:\n",
    "                print(f\"Skipping {file}: not enough samples ({len(real_part)} < {WINDOW_SIZE})\")\n",
    "                continue\n",
    "\n",
    "            # Extract window\n",
    "            i_window = real_part[:WINDOW_SIZE]\n",
    "            q_window = imag_part[:WINDOW_SIZE]\n",
    "            combined = np.vstack((i_window, q_window))  # shape: [2, WINDOW_SIZE]\n",
    "\n",
    "            # Create dataset and dataloader\n",
    "            test_dataset = IQDataset([combined], [TARGET_LABEL])\n",
    "            test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "            # Run prediction\n",
    "            with torch.no_grad():\n",
    "                for data in test_loader:\n",
    "                    images, labels = data\n",
    "                    images = images.to(DEVICE)\n",
    "                    outputs = model(images)\n",
    "                    probs = F.softmax(outputs, dim=1)\n",
    "                    pred = torch.argmax(probs, dim=1)\n",
    "                    conf = probs.max(dim=1).values\n",
    "                    print(f\"[{file}] Prediction: {pred.item()}, Confidence: {conf.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26caab07-c1af-444b-a6ed-8a1288354578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
