{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24029566-0319-415e-a758-c15b33d623bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c9506e-73e5-4b58-8bdd-a7d65c57a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            # input 4096 -> 2 channels instead of 1\n",
    "            nn.Conv1d(2, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size 912\n",
    "            nn.Conv1d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size 456\n",
    "            nn.Conv1d(128, 256, kernel_size=4,\n",
    "                      stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size 228\n",
    "            nn.Conv1d(256, 512, kernel_size=4,\n",
    "                      stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size 114\n",
    "            nn.Conv1d(512, 2, kernel_size=256, stride=1, padding=0, bias=False),  # output 2 channels instead of 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super().__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose1d(nz, 512, 256, 1, 0, bias=False),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose1d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose1d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose1d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose1d(64, 2, 4, 2, 1, bias=False),  # output 2 channels instead of 1\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7256b348-bb66-46fe-b2ca-425b43e96a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iq_data(file_path, max_samples=4096*2, start_idx=0):\n",
    "    total_samples = max_samples * 2  # Since I/Q samples are interleaved\n",
    "\n",
    "    #  Open the file in binary mode and seek to `start_idx`\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        f.seek(start_idx * 4 * 2)  # 4 bytes per float32, 2 channels (I/Q)\n",
    "        raw_data = np.fromfile(f, dtype=\"float32\", count=total_samples)\n",
    "\n",
    "    #  Ensure we have enough data\n",
    "    if raw_data.shape[0] < total_samples:\n",
    "        raise ValueError(f\"Not enough data in {file_path}. Requested {total_samples}, got {raw_data.shape[0]}.\")\n",
    "\n",
    "    #  Extract I/Q channels\n",
    "    I = raw_data[0::2]  # Even indices\n",
    "    Q = raw_data[1::2]  # Odd indices\n",
    "\n",
    "    #  Stack into [2, max_samples] format\n",
    "    iq_data = np.stack([I, Q], axis=0)\n",
    "\n",
    "    #  Add batch dimension â†’ [1, 2, max_samples]\n",
    "    iq_data = np.expand_dims(iq_data, axis=0)\n",
    "\n",
    "    #  Convert to PyTorch tensor\n",
    "    data_tensor = torch.from_numpy(iq_data).float()\n",
    "\n",
    "    #  Dummy label for now (adjust if needed)\n",
    "    label_tensor = torch.tensor([0], dtype=torch.long)\n",
    "\n",
    "    return data_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8339574c-1520-464c-8f83-5b85ba30242c",
   "metadata": {},
   "source": [
    "so there are three ideas that i had,\n",
    "1. Pass in the adv noise thats already effective against classifier into the gan. Gan extrapolates the noise to produce longer adversarial sequences of PGD. The discriminator learns to differentiate between real extended adversarial noise and the noise generated by your model but I dont think this is that useful\n",
    "2. Conditioning on prover signal by passing in the orignal clean block from prover and learns to gen noise based on the prover block and extrapolate for longer sequences. But I dont know how different this will be from idea 1, maybe can test this out. Discriminator makes less detectable im not sure\n",
    "3. this is where the innovation begins. maybe a hybrid of the two before where the GANs input are both the noise and the original sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e68155-0e16-40cd-ab72-caa50144c12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/32]\tLoss_D: 10.0131\tLoss_G: 6.6687\tD(x): 0.4259\tD(G(z)): 0.4297 / 0.1378\n",
      "[1/32]\tLoss_D: 5.8702\tLoss_G: 9.6166\tD(x): 0.7507\tD(G(z)): 0.8149 / 0.0026\n",
      "[2/32]\tLoss_D: 3.9565\tLoss_G: 7.7453\tD(x): 0.4284\tD(G(z)): 0.5765 / 0.0025\n",
      "[3/32]\tLoss_D: 4.8678\tLoss_G: 5.9124\tD(x): 0.3521\tD(G(z)): 0.5114 / 0.0553\n",
      "[4/32]\tLoss_D: 5.2927\tLoss_G: 4.2403\tD(x): 0.2668\tD(G(z)): 0.4262 / 0.0554\n",
      "[5/32]\tLoss_D: 6.9534\tLoss_G: 4.3220\tD(x): 0.3500\tD(G(z)): 0.5914 / 0.0730\n",
      "[6/32]\tLoss_D: 5.8195\tLoss_G: 7.0676\tD(x): 0.5538\tD(G(z)): 0.7453 / 0.0531\n",
      "[7/32]\tLoss_D: 4.0995\tLoss_G: 6.9774\tD(x): 0.4625\tD(G(z)): 0.6185 / 0.0032\n",
      "[8/32]\tLoss_D: 3.7989\tLoss_G: 7.4688\tD(x): 0.4457\tD(G(z)): 0.6583 / 0.0075\n",
      "[9/32]\tLoss_D: 6.6120\tLoss_G: 4.3044\tD(x): 0.3669\tD(G(z)): 0.5759 / 0.1090\n",
      "[10/32]\tLoss_D: 5.4871\tLoss_G: 4.2479\tD(x): 0.3057\tD(G(z)): 0.5595 / 0.0349\n",
      "[11/32]\tLoss_D: 5.4012\tLoss_G: 6.9598\tD(x): 0.6351\tD(G(z)): 0.7374 / 0.0120\n",
      "[12/32]\tLoss_D: 7.5041\tLoss_G: 6.0152\tD(x): 0.3945\tD(G(z)): 0.6364 / 0.0485\n",
      "[13/32]\tLoss_D: 7.9119\tLoss_G: 5.1406\tD(x): 0.1521\tD(G(z)): 0.4908 / 0.0425\n",
      "[14/32]\tLoss_D: 13.2429\tLoss_G: 4.2244\tD(x): 0.2341\tD(G(z)): 0.7000 / 0.1225\n",
      "[15/32]\tLoss_D: 7.1182\tLoss_G: 5.2911\tD(x): 0.5047\tD(G(z)): 0.8313 / 0.0545\n",
      "[16/32]\tLoss_D: 7.7104\tLoss_G: 6.7534\tD(x): 0.4508\tD(G(z)): 0.7872 / 0.0228\n",
      "[17/32]\tLoss_D: 6.9330\tLoss_G: 6.6161\tD(x): 0.2502\tD(G(z)): 0.6609 / 0.0104\n",
      "[18/32]\tLoss_D: 12.8161\tLoss_G: 3.5433\tD(x): 0.2155\tD(G(z)): 0.5424 / 0.1087\n",
      "[19/32]\tLoss_D: 6.6248\tLoss_G: 3.7005\tD(x): 0.3440\tD(G(z)): 0.5729 / 0.0898\n",
      "[20/32]\tLoss_D: 8.4016\tLoss_G: 3.8872\tD(x): 0.2453\tD(G(z)): 0.8089 / 0.1544\n",
      "[21/32]\tLoss_D: 10.8122\tLoss_G: 3.9027\tD(x): 0.3087\tD(G(z)): 0.8723 / 0.1804\n",
      "[22/32]\tLoss_D: 14.3156\tLoss_G: 5.0173\tD(x): 0.2417\tD(G(z)): 0.7899 / 0.1012\n",
      "[23/32]\tLoss_D: 14.3203\tLoss_G: 4.1226\tD(x): 0.3290\tD(G(z)): 0.7245 / 0.1382\n",
      "[24/32]\tLoss_D: 11.1644\tLoss_G: 3.9805\tD(x): 0.3250\tD(G(z)): 0.8103 / 0.1883\n",
      "[25/32]\tLoss_D: 8.8356\tLoss_G: 5.0655\tD(x): 0.1008\tD(G(z)): 0.7728 / 0.0370\n",
      "[26/32]\tLoss_D: 8.1330\tLoss_G: 4.9451\tD(x): 0.2146\tD(G(z)): 0.7770 / 0.0690\n",
      "[27/32]\tLoss_D: 10.8291\tLoss_G: 2.1638\tD(x): 0.0557\tD(G(z)): 0.7549 / 0.2684\n",
      "[28/32]\tLoss_D: 21.7632\tLoss_G: 2.9174\tD(x): 0.4680\tD(G(z)): 0.8936 / 0.3331\n",
      "[29/32]\tLoss_D: 8.2097\tLoss_G: 5.6412\tD(x): 0.2568\tD(G(z)): 0.8066 / 0.0282\n",
      "[30/32]\tLoss_D: 9.0545\tLoss_G: 5.5467\tD(x): 0.3037\tD(G(z)): 0.7800 / 0.0144\n",
      "[31/32]\tLoss_D: 8.0754\tLoss_G: 5.5396\tD(x): 0.4256\tD(G(z)): 0.8123 / 0.0730\n"
     ]
    }
   ],
   "source": [
    "adv_noise_path = \"2m_0target3_noise.iq\"\n",
    "data_tensor, label_tensor = load_iq_data(IQ_FILE_PATH, max_samples=max_samples)\n",
    "data_tensor = data_tensor.to(DEVICE)\n",
    "\n",
    "\n",
    "lr = 2e-4\n",
    "beta1 = 0.5\n",
    "epoch_num = 32\n",
    "batch_size = 8\n",
    "nz = 100  # length of noise\n",
    "ngpu = 0\n",
    "input_size = 4096  # Size of input sequence\n",
    "num_channels = 2\n",
    "label_size = batch_size * num_channels\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# init netD and netG\n",
    "netD = Discriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "netG = Generator(nz).to(device)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# used for visualizing training process\n",
    "fixed_noise = torch.randn(16, nz, 1, device=device)\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    # Create labels\n",
    "    real_labels = torch.ones(batch_size, num_channels).to(device)  # Real labels with 2 channels\n",
    "    fake_labels = torch.zeros(batch_size, num_channels).to(device)  # Fake labels with 2 channels\n",
    "\n",
    "    # Create real data (e.g., use random noise as a placeholder for real data)\n",
    "    real_data = torch.randn(batch_size, num_channels, input_size).to(device)  # Real data with 2 channels\n",
    "        \n",
    "    real_cpu = real_data.to(device)\n",
    "    b_size = real_cpu.size(0)\n",
    "\n",
    "    # train netD\n",
    "    label = torch.full((label_size,), real_label,\n",
    "                       dtype=torch.float, device=device)\n",
    "    netD.zero_grad()\n",
    "    output = netD(real_cpu).view(-1)\n",
    "    \n",
    "    errD_real = criterion(output, label)\n",
    "    errD_real.backward()\n",
    "    D_x = output.mean().item()\n",
    "\n",
    "    # train netG\n",
    "    noise = torch.randn(b_size, nz, 1, device=device)\n",
    "    fake = netG(noise)\n",
    "    label.fill_(fake_label)\n",
    "    output = netD(fake.detach()).view(-1)\n",
    "    errD_fake = criterion(output, label)\n",
    "    errD_fake.backward()\n",
    "    D_G_z1 = output.mean().item()\n",
    "    errD = errD_real + errD_fake\n",
    "    optimizerD.step()\n",
    "    netG.zero_grad()\n",
    "\n",
    "    label.fill_(real_label)\n",
    "    output = netD(fake).view(-1)\n",
    "    errG = criterion(output, label)\n",
    "    errG.backward()\n",
    "    D_G_z2 = output.mean().item()\n",
    "    optimizerG.step()\n",
    "\n",
    "    print('[%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "          % (epoch, epoch_num,\n",
    "             errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e9094-fa95-437a-a023-c61a66323274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cde536-78bf-4162-b707-9dd6e1811313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
