{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67486927-e138-4105-9d17-b308a17baf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained model weights from: /home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model_retrained.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_342067/1088263118.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet1D(\n",
       "  (conv1): Conv1d(2, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck1D(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck1D(\n",
       "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Bottleneck1D(\n",
       "      (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck1D(\n",
       "      (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck1D(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Bottleneck1D(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Bottleneck1D(\n",
       "      (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck1D(\n",
       "      (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck1D(\n",
       "      (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(2,), bias=False)\n",
       "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck1D(\n",
       "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): Bottleneck1D(\n",
       "      (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=2048, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F  \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "EPSILON = 0.1       # Max perturbation (for L∞ PGD)\n",
    "ALPHA = 0.01         # Step size per iteration\n",
    "ATTACK_ITERATIONS = 40\n",
    "TARGET_LABEL = 2     # Example target label for the targeted attack\n",
    "\n",
    "# System/Model parameters\n",
    "sys.path.append(\"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/models\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/weights/best_model_retrained.pth\"\n",
    "#IQ_FILE_PATH = \"/home/jfeng/Desktop/jfeng/rf_spoofing/spoofing/1m_2m_replacedPluto4/Pluto_10_windows_runs2_3/Pluto_10_2m_run3.iq\"\n",
    "IQ_FILE_PATH = \"May22Test/Pluto10_2m.iq\"\n",
    "\n",
    "from attempt2 import resnet50_1d  # Directly import from attempt2.py\n",
    "num_classes = 8  # Change this if your model was trained with a different number of classes\n",
    "\n",
    "# Initialize the model architecture\n",
    "model = resnet50_1d(num_classes=num_classes).to(DEVICE)\n",
    "\n",
    "# Load trained weights\n",
    "print(f\"Loading trained model weights from: {MODEL_PATH}\")\n",
    "state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f389dff9-ba8b-4a9a-8c12-775b9e997549",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IQDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        sample = torch.from_numpy(sample).float()\n",
    "        # Normalize data\n",
    "        magnitude = torch.sqrt(torch.sum(sample**2, dim=1, keepdim=True))\n",
    "        sample = sample / magnitude\n",
    "\n",
    "        label_tensors = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return sample, label_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7d825e-990c-477c-9efc-93e3cb2af9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "WINDOW_SIZE = 10000\n",
    "HOP_SIZE = 500\n",
    "START_INDEX = 4800\n",
    "END_INDEX = 6000\n",
    "\n",
    "def path_loss(signal, n, d1, d2):\n",
    "    scaling = (d1 / d2) ** (n / 2)\n",
    "    return signal * scaling\n",
    "\n",
    "def apply_rician_fading(signal, K=10.0):\n",
    "    \"\"\"\n",
    "    Apply Rician fading to the signal, which is of shape [2, N] (I and Q).\n",
    "    Fading is applied using a K-factor (default 10).\n",
    "    \"\"\"\n",
    "    i_window = signal[:, 0, :]\n",
    "    q_window = signal[:, 1, :]\n",
    "\n",
    "    device = signal.device\n",
    "    dtype = signal.dtype\n",
    "    # Calculate scaling factors\n",
    "    K = torch.tensor(K, dtype=dtype, device=device)\n",
    "    scale_LOS = torch.sqrt(K / (K + 1))\n",
    "    scale_NLOS = torch.sqrt(1 / (K + 1))\n",
    "\n",
    "    # Generate NLOS (Rayleigh) component\n",
    "    real_nlos = torch.randn(i_window.shape, device=device) / torch.sqrt(torch.tensor(2.0, dtype=dtype, device=device))\n",
    "    imag_nlos = torch.randn(i_window.shape, device=device) / torch.sqrt(torch.tensor(2.0, dtype=dtype, device=device))\n",
    "\n",
    "    # LOS component (typically assumed as 1 + 0j for all samples)\n",
    "    real_los = torch.ones(i_window.shape, device=device)\n",
    "    imag_los = torch.zeros(i_window.shape, device=device)\n",
    "\n",
    "    # Total fading coefficients\n",
    "    real_fade = scale_LOS * real_los + scale_NLOS * real_nlos\n",
    "    imag_fade = scale_LOS * imag_los + scale_NLOS * imag_nlos\n",
    "\n",
    "    # Apply Rician fading\n",
    "    faded_real = i_window * real_fade - q_window * imag_fade\n",
    "    faded_imag = i_window * imag_fade + q_window * real_fade\n",
    "\n",
    "    # Reconstruct the faded signal back into a tensor\n",
    "    faded_signal = torch.stack((faded_real, faded_imag), dim=1)\n",
    "\n",
    "    return faded_signal\n",
    "\n",
    "def apply_awgn(signal, noise_std=0.000001):\n",
    "    device = signal.device\n",
    "    dtype = signal.dtype\n",
    "    # Split noise equally between I and Q (to maintain total variance)\n",
    "    per_dim_std = noise_std / torch.sqrt(torch.tensor(2.0, dtype=dtype, device=device))\n",
    "    # Generate i.i.d. Gaussian noise for I and Q\n",
    "    noise = torch.randn_like(signal, device=device) * per_dim_std\n",
    "    # Add noise to the signal\n",
    "    noisy_signal = signal + noise\n",
    "\n",
    "    return noisy_signal\n",
    "\n",
    "def transform_channel_effects(x, chosen_distance=2.0, path_loss_exponent=2.0, reference_distance=1.0, noise_std=0.000001, k=10.0):   \n",
    "    #print(\"Signal original: \", x)\n",
    "    signal_path_loss = path_loss(x, path_loss_exponent, reference_distance, chosen_distance)\n",
    "    #print(\"Signal Path Loss: \", signal_path_loss)\n",
    "    signal_rician = apply_rician_fading(signal_path_loss, k)\n",
    "    #print(\"Signal Rician: \", signal_rician)\n",
    "    signal_awgn = apply_awgn(signal_rician, noise_std)\n",
    "    #print(\"Signal AWGN: \", signal_awgn)\n",
    "    return signal_awgn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d681ac-5c37-4371-837f-a9a5411fe41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def targeted_eot_pgd_attack(\n",
    "    model,\n",
    "    x,\n",
    "    perturb,\n",
    "    y,\n",
    "    target_label,\n",
    "    eps=0.1,\n",
    "    alpha=0.01,\n",
    "    num_iter=40,\n",
    "    num_samples=10,\n",
    "    min_distance=1.0,\n",
    "    max_distance=4.0,\n",
    "    path_loss_exponent=2.0,\n",
    "    reference_distance=1.0,\n",
    "    min_noise_std=0.000001,\n",
    "    max_noise_std=0.0001,\n",
    "    min_k=10,\n",
    "    max_k=20\n",
    "):\n",
    "    x_adv = perturb.clone().detach().requires_grad_(True).to(DEVICE)\n",
    "    target = torch.full_like(y, target_label)\n",
    "\n",
    "    best_x_adv = x_adv.clone().detach()\n",
    "    best_target_confidence = -float('inf')\n",
    "    # PGD Iterations\n",
    "    for i in range(num_iter):\n",
    "        total_grad = torch.zeros_like(x_adv)\n",
    "        grads = []\n",
    "        # EOT Iterations\n",
    "        for _ in range(num_samples):\n",
    "            all_logits = []\n",
    "            # Choose a random distance between min and max, for this EOT iteration\n",
    "            chosen_distance = torch.empty(1).uniform_(min_distance, max_distance + 0.0000001).item()\n",
    "            chosen_k = torch.empty(1).uniform_(min_k, max_k + 0.0000001).item()\n",
    "            chosen_noise_std = torch.empty(1).uniform_(min_noise_std, max_noise_std + 0.0000001).item()\n",
    "            x_t = transform_channel_effects(\n",
    "                x_adv,\n",
    "                chosen_distance=chosen_distance,\n",
    "                path_loss_exponent=path_loss_exponent,\n",
    "                reference_distance=reference_distance,\n",
    "                noise_std=chosen_noise_std,\n",
    "                k=chosen_k\n",
    "            )\n",
    "            x_combined = x_t + x\n",
    "            logits = model(x_combined)\n",
    "            all_logits.append(logits)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "\n",
    "            grad = torch.autograd.grad(loss, x_adv, retain_graph=False, create_graph=False)[0]\n",
    "            grads.append(grad.detach())\n",
    "            total_grad += grad\n",
    "\n",
    "        grads_tensor = torch.stack(grads)\n",
    "        grad_variance = grads_tensor.var(dim=0).mean().item()\n",
    "        print(f\"PGD step {i + 1}/{num_iter}: gradient variance = {grad_variance:.4e}\")\n",
    "        avg_grad = total_grad / num_samples\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_adv -= alpha * avg_grad.sign()\n",
    "            x_adv = torch.max(torch.min(x_adv, x + eps), x - eps)\n",
    "            x_adv = x_adv.detach().clone().requires_grad_(True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_logits = torch.stack(all_logits).mean(dim=0)\n",
    "            target_confidence = F.softmax(avg_logits, dim=1)[:, target_label]  # shape: [batch]\n",
    "            avg_conf = target_confidence.mean().item()\n",
    "\n",
    "            if avg_conf > best_target_confidence:\n",
    "                best_target_confidence = avg_conf\n",
    "                best_x_adv = x_adv.clone().detach()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Choose a random distance between min and max, for this EOT iteration\n",
    "            chosen_distance = torch.empty(1).uniform_(min_distance, max_distance + 0.0000001).item()\n",
    "            chosen_k = torch.empty(1).uniform_(min_k, max_k + 0.0000001).item()\n",
    "            chosen_noise_std = torch.empty(1).uniform_(min_noise_std, max_noise_std + 0.0000001).item()\n",
    "            x_t = transform_channel_effects(\n",
    "                x_adv,\n",
    "                chosen_distance=chosen_distance,\n",
    "                path_loss_exponent=path_loss_exponent,\n",
    "                reference_distance=reference_distance,\n",
    "                noise_std=chosen_noise_std,\n",
    "                k=chosen_k\n",
    "            )\n",
    "            x_combined = x_t + x\n",
    "            pred = model(x_combined).argmax(dim=1)\n",
    "            success = (pred == target).float().mean().item()\n",
    "            print(f\"Attack success rate: {success * 100:.2f}%\")\n",
    "\n",
    "    return best_x_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e397fc96-c869-45bb-9d31-09d9ae97693f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: May22Test/Pluto10_2m.iq\n",
      "True label: 10, Target label: 2\n",
      "PGD step 1/60: gradient variance = 1.3956e+01\n",
      "Attack success rate: 0.00%\n",
      "PGD step 2/60: gradient variance = 5.5298e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 3/60: gradient variance = 6.2043e-34\n",
      "Attack success rate: 0.00%\n",
      "PGD step 4/60: gradient variance = 2.5961e+01\n",
      "Attack success rate: 100.00%\n",
      "PGD step 5/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 6/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 7/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 8/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 9/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 10/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 11/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 12/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 13/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 14/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 15/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 16/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 17/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 18/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 19/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 20/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 21/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 22/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 23/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 24/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 25/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 26/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 27/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 28/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 29/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 30/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 31/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 32/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 33/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 34/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 35/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 36/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 37/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 38/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 39/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 40/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 41/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 42/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 43/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 44/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 45/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 46/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 47/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 48/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 49/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 50/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 51/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 52/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 53/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 54/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 55/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 56/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 57/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 58/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 59/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "PGD step 60/60: gradient variance = 0.0000e+00\n",
      "Attack success rate: 100.00%\n",
      "Saved EoT PGD *noise* to May22Test/acc2m.iq\n"
     ]
    }
   ],
   "source": [
    "def generate_eot_pgd_noise():\n",
    "    print(f\"Loading data from: {IQ_FILE_PATH}\")\n",
    "    label = 10\n",
    "    print(f\"True label: {label}, Target label: {TARGET_LABEL}\")\n",
    "\n",
    "    # Load IQ data\n",
    "    data = np.fromfile(IQ_FILE_PATH, dtype=\"float32\")\n",
    "    real = data[0::2]\n",
    "    imag = data[1::2]\n",
    "    start = (START_INDEX + 1) * HOP_SIZE\n",
    "    end = start + WINDOW_SIZE\n",
    "    i_window = real[start:end]\n",
    "    q_window = imag[start:end]\n",
    "    combined = np.vstack((i_window, q_window))  # [2, N]\n",
    "\n",
    "    # Format into dataset\n",
    "    test_dataset = IQDataset([combined], [label])\n",
    "    data_tensor, label_tensor = test_dataset[0]\n",
    "    data_tensor = data_tensor.unsqueeze(0).to(DEVICE)\n",
    "    #label_tensor = label_tensor.unsqueeze(0).to(DEVICE)\n",
    "    #----------------------------------------------------------\n",
    "    perturbation_tensor = torch.empty((1, 2, WINDOW_SIZE), dtype=torch.float32).uniform_(-0.1, 0.1).to(DEVICE)\n",
    "    label_tensor = torch.tensor([label], dtype=torch.long).to(DEVICE)\n",
    "    #----------------------------------------------------------\n",
    "    min_distance=1.0\n",
    "    max_distance=4.0\n",
    "    min_k = 20\n",
    "    max_k = 20\n",
    "    min_noise_std = 0.000001\n",
    "    max_noise_std = 0.000001\n",
    "    path_loss_exponent=2.0\n",
    "    reference_distance=1.0\n",
    "    EPSILON = 0.1\n",
    "    ALPHA = 0.01\n",
    "    ATTACK_ITERATIONS = 60\n",
    "    if min_distance >= 5.0:\n",
    "        EPSILON = 0.6\n",
    "        ALPHA = 0.021\n",
    "        ATTACK_ITERATIONS = 100\n",
    "\n",
    "    # EoT PGD attack\n",
    "    x_adv = targeted_eot_pgd_attack(\n",
    "        model=model,\n",
    "        x=data_tensor,\n",
    "        perturb=perturbation_tensor,\n",
    "        y=label_tensor,\n",
    "        target_label=TARGET_LABEL,\n",
    "        eps=EPSILON,\n",
    "        alpha=ALPHA,\n",
    "        num_iter=ATTACK_ITERATIONS,\n",
    "        num_samples=10,\n",
    "        min_distance=min_distance,\n",
    "        max_distance=max_distance,\n",
    "        path_loss_exponent=path_loss_exponent,\n",
    "        reference_distance=reference_distance,\n",
    "        min_noise_std=min_noise_std,\n",
    "        max_noise_std=max_noise_std,\n",
    "        min_k=min_k,\n",
    "        max_k=max_k\n",
    "    )\n",
    "\n",
    "    # Save perturbation only\n",
    "    original_np = data_tensor.squeeze().cpu().numpy()\n",
    "\n",
    "    adv_np = x_adv.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    noise_np = adv_np-original_np\n",
    "\n",
    "    interleaved_noise = np.empty(noise_np.shape[1] * 2, dtype=np.float32)\n",
    "    interleaved_noise[0::2] = noise_np[0]\n",
    "    interleaved_noise[1::2] = noise_np[1]\n",
    "\n",
    "    # write out the noise file\n",
    "    save_path = \"May22Test/acc2m.iq\"\n",
    "    interleaved_noise.tofile(save_path)\n",
    "    print(f\"Saved EoT PGD *noise* to {save_path}\")\n",
    "\n",
    "\n",
    "generate_eot_pgd_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "398b200d-e48f-475c-a9c5-1e2d57e83f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def targeted_eot_pgd_attack2(\n",
    "    model,\n",
    "    x,\n",
    "    perturb,\n",
    "    y,\n",
    "    target_label,\n",
    "    eps=0.1,\n",
    "    alpha=0.01,\n",
    "    num_iter=40,\n",
    "    num_samples=10,\n",
    "    min_distance=1.0,\n",
    "    max_distance=4.0,\n",
    "    path_loss_exponent=2.0,\n",
    "    reference_distance=1.0,\n",
    "    min_noise_std=0.000001,\n",
    "    max_noise_std=0.0001,\n",
    "    min_k=10,\n",
    "    max_k=20\n",
    "):\n",
    "    x_acc = perturb.clone().detach().requires_grad_(True).to(DEVICE)\n",
    "    target = torch.full_like(y, target_label)\n",
    "\n",
    "    best_x_acc = x_acc.clone().detach()\n",
    "    best_target_confidence = -float('inf')\n",
    "    # PGD Iterations\n",
    "    for i in range(num_iter):\n",
    "        total_grad = torch.zeros_like(x_acc)\n",
    "        grads = []\n",
    "        # EOT Iterations\n",
    "        for _ in range(num_samples):\n",
    "            all_logits = []\n",
    "            # Choose a random distance between min and max, for this EOT iteration\n",
    "            chosen_distance = torch.empty(1).uniform_(min_distance, max_distance + 0.0000001).item()\n",
    "            chosen_k = torch.empty(1).uniform_(min_k, max_k + 0.0000001).item()\n",
    "            chosen_noise_std = torch.empty(1).uniform_(min_noise_std, max_noise_std + 0.0000001).item()\n",
    "            x_t = transform_channel_effects(\n",
    "                x_acc,\n",
    "                chosen_distance=chosen_distance,\n",
    "                path_loss_exponent=path_loss_exponent,\n",
    "                reference_distance=reference_distance,\n",
    "                noise_std=chosen_noise_std,\n",
    "                k=chosen_k\n",
    "            )\n",
    "            d_tx   = float(torch.empty(1).uniform_(min_distance, max_distance))\n",
    "            sigma_tx   = float(torch.empty(1).uniform_(min_noise_std, max_noise_std))\n",
    "            k_tx   = float(torch.empty(1).uniform_(min_k, max_k))\n",
    "            x_tx_t = transform_channel_effects(\n",
    "                x,\n",
    "                chosen_distance=d_tx,\n",
    "                path_loss_exponent=path_loss_exponent,\n",
    "                reference_distance=reference_distance,\n",
    "                noise_std=sigma_tx,\n",
    "                k=k_tx\n",
    "            )\n",
    "            x_combined = x_t + x_tx_t\n",
    "            logits = model(x_combined)\n",
    "            all_logits.append(logits)\n",
    "            loss = F.cross_entropy(logits, target)\n",
    "\n",
    "            grad = torch.autograd.grad(loss, x_acc, retain_graph=False, create_graph=False)[0]\n",
    "            grads.append(grad.detach())\n",
    "            total_grad += grad\n",
    "\n",
    "        grads_tensor = torch.stack(grads)\n",
    "        grad_variance = grads_tensor.var(dim=0).mean().item()\n",
    "        print(f\"PGD step {i + 1}/{num_iter}: gradient variance = {grad_variance:.4e}\")\n",
    "        avg_grad = total_grad / num_samples\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x_acc -= alpha * avg_grad.sign()\n",
    "            x_acc = torch.max(torch.min(x_acc, x + eps), x - eps)\n",
    "            x_acc = x_acc.detach().clone().requires_grad_(True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            avg_logits = torch.stack(all_logits).mean(dim=0)\n",
    "            target_confidence = F.softmax(avg_logits, dim=1)[:, target_label]  # shape: [batch]\n",
    "            avg_conf = target_confidence.mean().item()\n",
    "\n",
    "            if avg_conf > best_target_confidence:\n",
    "                best_target_confidence = avg_conf\n",
    "                best_x_acc = x_acc.clone().detach()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Choose a random distance between min and max, for this EOT iteration\n",
    "            chosen_distance = torch.empty(1).uniform_(min_distance, max_distance + 0.0000001).item()\n",
    "            chosen_k = torch.empty(1).uniform_(min_k, max_k + 0.0000001).item()\n",
    "            chosen_noise_std = torch.empty(1).uniform_(min_noise_std, max_noise_std + 0.0000001).item()\n",
    "            x_t = transform_channel_effects(\n",
    "                x_acc,\n",
    "                chosen_distance=chosen_distance,\n",
    "                path_loss_exponent=path_loss_exponent,\n",
    "                reference_distance=reference_distance,\n",
    "                noise_std=chosen_noise_std,\n",
    "                k=chosen_k\n",
    "            )\n",
    "            x_combined = x_t + x\n",
    "            pred = model(x_combined).argmax(dim=1)\n",
    "            success = (pred == target).float().mean().item()\n",
    "            print(f\"Attack success rate: {success * 100:.2f}%\")\n",
    "\n",
    "    return best_x_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5984ece-a10e-4a77-be33-911f67344cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
